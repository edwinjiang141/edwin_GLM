{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.08726079634202742,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 4.51372766494751,
      "learning_rate": 4.995e-05,
      "loss": 4.5158,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.509660243988037,
      "learning_rate": 4.99e-05,
      "loss": 4.9695,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.897611141204834,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 4.7072,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.925756454467773,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 4.86,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.76296854019165,
      "learning_rate": 4.975e-05,
      "loss": 4.3152,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.053510665893555,
      "learning_rate": 4.97e-05,
      "loss": 4.2143,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.341315746307373,
      "learning_rate": 4.965e-05,
      "loss": 3.7428,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.942869663238525,
      "learning_rate": 4.96e-05,
      "loss": 3.8846,
      "step": 80
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.096568584442139,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 3.5521,
      "step": 90
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.488510608673096,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 4.0213,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.116507053375244,
      "learning_rate": 4.945e-05,
      "loss": 3.7584,
      "step": 110
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.46156120300293,
      "learning_rate": 4.94e-05,
      "loss": 4.1396,
      "step": 120
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.4285149574279785,
      "learning_rate": 4.935e-05,
      "loss": 3.8271,
      "step": 130
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.492930889129639,
      "learning_rate": 4.93e-05,
      "loss": 3.7023,
      "step": 140
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.685804843902588,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 3.4889,
      "step": 150
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.05703067779541,
      "learning_rate": 4.92e-05,
      "loss": 3.6287,
      "step": 160
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.144443511962891,
      "learning_rate": 4.915e-05,
      "loss": 3.7414,
      "step": 170
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.9310832023620605,
      "learning_rate": 4.91e-05,
      "loss": 3.9301,
      "step": 180
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.309390068054199,
      "learning_rate": 4.905e-05,
      "loss": 3.7133,
      "step": 190
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.719120979309082,
      "learning_rate": 4.9e-05,
      "loss": 3.708,
      "step": 200
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.190303325653076,
      "learning_rate": 4.8950000000000004e-05,
      "loss": 3.3627,
      "step": 210
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.93036413192749,
      "learning_rate": 4.89e-05,
      "loss": 3.7137,
      "step": 220
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.747474670410156,
      "learning_rate": 4.885e-05,
      "loss": 3.5135,
      "step": 230
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.051882266998291,
      "learning_rate": 4.88e-05,
      "loss": 3.7414,
      "step": 240
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.769023418426514,
      "learning_rate": 4.875e-05,
      "loss": 3.552,
      "step": 250
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.494219779968262,
      "learning_rate": 4.87e-05,
      "loss": 3.6316,
      "step": 260
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.907341957092285,
      "learning_rate": 4.8650000000000003e-05,
      "loss": 3.5887,
      "step": 270
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.62356948852539,
      "learning_rate": 4.86e-05,
      "loss": 3.568,
      "step": 280
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.6363420486450195,
      "learning_rate": 4.855e-05,
      "loss": 3.5539,
      "step": 290
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.96117639541626,
      "learning_rate": 4.85e-05,
      "loss": 3.6395,
      "step": 300
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.287398338317871,
      "learning_rate": 4.845e-05,
      "loss": 3.6193,
      "step": 310
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.266576766967773,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 3.5018,
      "step": 320
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.638065338134766,
      "learning_rate": 4.835e-05,
      "loss": 3.4035,
      "step": 330
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.14788818359375,
      "learning_rate": 4.83e-05,
      "loss": 3.4928,
      "step": 340
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.640882968902588,
      "learning_rate": 4.825e-05,
      "loss": 3.4438,
      "step": 350
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.324162483215332,
      "learning_rate": 4.82e-05,
      "loss": 3.4359,
      "step": 360
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.806087017059326,
      "learning_rate": 4.815e-05,
      "loss": 3.568,
      "step": 370
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.282551765441895,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 3.5551,
      "step": 380
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.317830085754395,
      "learning_rate": 4.805e-05,
      "loss": 3.6361,
      "step": 390
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.22360897064209,
      "learning_rate": 4.8e-05,
      "loss": 3.4504,
      "step": 400
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.057903289794922,
      "learning_rate": 4.795e-05,
      "loss": 3.2852,
      "step": 410
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.552923202514648,
      "learning_rate": 4.79e-05,
      "loss": 3.6932,
      "step": 420
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.992903709411621,
      "learning_rate": 4.785e-05,
      "loss": 3.5258,
      "step": 430
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.328750610351562,
      "learning_rate": 4.78e-05,
      "loss": 3.149,
      "step": 440
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.184255599975586,
      "learning_rate": 4.775e-05,
      "loss": 3.7404,
      "step": 450
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.689122200012207,
      "learning_rate": 4.77e-05,
      "loss": 3.7404,
      "step": 460
    },
    {
      "epoch": 0.0,
      "grad_norm": 13.551239967346191,
      "learning_rate": 4.765e-05,
      "loss": 3.8258,
      "step": 470
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.129018783569336,
      "learning_rate": 4.76e-05,
      "loss": 3.292,
      "step": 480
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.806016445159912,
      "learning_rate": 4.755e-05,
      "loss": 3.4154,
      "step": 490
    },
    {
      "epoch": 0.0,
      "grad_norm": 11.63790512084961,
      "learning_rate": 4.75e-05,
      "loss": 3.4596,
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_bleu-4": 0.03520715179865165,
      "eval_rouge-1": 29.836897999999998,
      "eval_rouge-2": 6.247331999999999,
      "eval_rouge-l": 23.645512000000004,
      "eval_runtime": 50.428,
      "eval_samples_per_second": 0.992,
      "eval_steps_per_second": 0.139,
      "step": 500
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.003782272338867,
      "learning_rate": 4.745e-05,
      "loss": 3.5298,
      "step": 510
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.66148853302002,
      "learning_rate": 4.74e-05,
      "loss": 3.5154,
      "step": 520
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.91796875,
      "learning_rate": 4.735e-05,
      "loss": 3.648,
      "step": 530
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.065116882324219,
      "learning_rate": 4.73e-05,
      "loss": 3.4559,
      "step": 540
    },
    {
      "epoch": 0.0,
      "grad_norm": 9.230608940124512,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 3.4756,
      "step": 550
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.89809513092041,
      "learning_rate": 4.72e-05,
      "loss": 3.574,
      "step": 560
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.052406311035156,
      "learning_rate": 4.715e-05,
      "loss": 3.5014,
      "step": 570
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.215739250183105,
      "learning_rate": 4.71e-05,
      "loss": 3.5049,
      "step": 580
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.933597564697266,
      "learning_rate": 4.705e-05,
      "loss": 3.7742,
      "step": 590
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.107051849365234,
      "learning_rate": 4.7e-05,
      "loss": 3.2492,
      "step": 600
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.478462219238281,
      "learning_rate": 4.695e-05,
      "loss": 3.3854,
      "step": 610
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.063422203063965,
      "learning_rate": 4.69e-05,
      "loss": 3.6408,
      "step": 620
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.8383150100708,
      "learning_rate": 4.685000000000001e-05,
      "loss": 3.7125,
      "step": 630
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.170687675476074,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 3.5676,
      "step": 640
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.73523235321045,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 3.273,
      "step": 650
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.369815826416016,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 3.4223,
      "step": 660
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.678451538085938,
      "learning_rate": 4.665e-05,
      "loss": 3.492,
      "step": 670
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.656071662902832,
      "learning_rate": 4.660000000000001e-05,
      "loss": 3.4516,
      "step": 680
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.379459381103516,
      "learning_rate": 4.655000000000001e-05,
      "loss": 3.4619,
      "step": 690
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.355896949768066,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 3.341,
      "step": 700
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.416969299316406,
      "learning_rate": 4.6450000000000004e-05,
      "loss": 3.5271,
      "step": 710
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.785049438476562,
      "learning_rate": 4.64e-05,
      "loss": 3.4572,
      "step": 720
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.18889045715332,
      "learning_rate": 4.635e-05,
      "loss": 3.4561,
      "step": 730
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.157285690307617,
      "learning_rate": 4.630000000000001e-05,
      "loss": 3.5959,
      "step": 740
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.42332649230957,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 3.2494,
      "step": 750
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.309723854064941,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 3.448,
      "step": 760
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.883041381835938,
      "learning_rate": 4.6150000000000004e-05,
      "loss": 3.5059,
      "step": 770
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.827044486999512,
      "learning_rate": 4.61e-05,
      "loss": 3.3494,
      "step": 780
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.597702026367188,
      "learning_rate": 4.605e-05,
      "loss": 3.4441,
      "step": 790
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.410441398620605,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.3561,
      "step": 800
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.555903434753418,
      "learning_rate": 4.5950000000000006e-05,
      "loss": 3.31,
      "step": 810
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.744560241699219,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 3.4125,
      "step": 820
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.009390830993652,
      "learning_rate": 4.585e-05,
      "loss": 3.492,
      "step": 830
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.707539558410645,
      "learning_rate": 4.58e-05,
      "loss": 3.4377,
      "step": 840
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.576884269714355,
      "learning_rate": 4.575e-05,
      "loss": 3.4539,
      "step": 850
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.6976318359375,
      "learning_rate": 4.5700000000000006e-05,
      "loss": 3.7443,
      "step": 860
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.54659366607666,
      "learning_rate": 4.5650000000000005e-05,
      "loss": 3.4096,
      "step": 870
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.45814323425293,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 3.549,
      "step": 880
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.943245887756348,
      "learning_rate": 4.555e-05,
      "loss": 3.6564,
      "step": 890
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.461847305297852,
      "learning_rate": 4.55e-05,
      "loss": 3.4008,
      "step": 900
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.849794387817383,
      "learning_rate": 4.545000000000001e-05,
      "loss": 3.2859,
      "step": 910
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.595078468322754,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 3.2725,
      "step": 920
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.836371421813965,
      "learning_rate": 4.5350000000000005e-05,
      "loss": 3.4984,
      "step": 930
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.132198333740234,
      "learning_rate": 4.53e-05,
      "loss": 3.2453,
      "step": 940
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.900152206420898,
      "learning_rate": 4.525e-05,
      "loss": 3.208,
      "step": 950
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.588577270507812,
      "learning_rate": 4.52e-05,
      "loss": 3.502,
      "step": 960
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.385787963867188,
      "learning_rate": 4.5150000000000006e-05,
      "loss": 3.2145,
      "step": 970
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.228181838989258,
      "learning_rate": 4.5100000000000005e-05,
      "loss": 3.4896,
      "step": 980
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.767592430114746,
      "learning_rate": 4.5050000000000004e-05,
      "loss": 3.3006,
      "step": 990
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.926527976989746,
      "learning_rate": 4.5e-05,
      "loss": 3.4818,
      "step": 1000
    },
    {
      "epoch": 0.01,
      "eval_bleu-4": 0.034989678270677047,
      "eval_rouge-1": 30.408646000000005,
      "eval_rouge-2": 5.908498,
      "eval_rouge-l": 24.040449999999996,
      "eval_runtime": 49.9973,
      "eval_samples_per_second": 1.0,
      "eval_steps_per_second": 0.14,
      "step": 1000
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.085931777954102,
      "learning_rate": 4.495e-05,
      "loss": 3.3914,
      "step": 1010
    },
    {
      "epoch": 0.01,
      "grad_norm": 14.840470314025879,
      "learning_rate": 4.49e-05,
      "loss": 3.4803,
      "step": 1020
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.559063911437988,
      "learning_rate": 4.4850000000000006e-05,
      "loss": 3.7246,
      "step": 1030
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.070165634155273,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 3.4178,
      "step": 1040
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.73782730102539,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 3.2832,
      "step": 1050
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.02669620513916,
      "learning_rate": 4.47e-05,
      "loss": 3.383,
      "step": 1060
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.598028182983398,
      "learning_rate": 4.465e-05,
      "loss": 3.5525,
      "step": 1070
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.858383178710938,
      "learning_rate": 4.46e-05,
      "loss": 3.583,
      "step": 1080
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.210222244262695,
      "learning_rate": 4.4550000000000005e-05,
      "loss": 3.4914,
      "step": 1090
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.513162612915039,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 3.5525,
      "step": 1100
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.893457412719727,
      "learning_rate": 4.445e-05,
      "loss": 3.4361,
      "step": 1110
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.482068061828613,
      "learning_rate": 4.44e-05,
      "loss": 3.3064,
      "step": 1120
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.207565307617188,
      "learning_rate": 4.435e-05,
      "loss": 3.2629,
      "step": 1130
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.681825637817383,
      "learning_rate": 4.43e-05,
      "loss": 3.698,
      "step": 1140
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.389178276062012,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 3.4676,
      "step": 1150
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.088705062866211,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 3.4424,
      "step": 1160
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.817840576171875,
      "learning_rate": 4.415e-05,
      "loss": 3.2969,
      "step": 1170
    },
    {
      "epoch": 0.01,
      "grad_norm": 18.411849975585938,
      "learning_rate": 4.41e-05,
      "loss": 3.2268,
      "step": 1180
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.817453384399414,
      "learning_rate": 4.405e-05,
      "loss": 3.5639,
      "step": 1190
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.521563529968262,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.4025,
      "step": 1200
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.079299926757812,
      "learning_rate": 4.3950000000000004e-05,
      "loss": 3.3072,
      "step": 1210
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.209625244140625,
      "learning_rate": 4.39e-05,
      "loss": 3.4277,
      "step": 1220
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.621901512145996,
      "learning_rate": 4.385e-05,
      "loss": 3.2248,
      "step": 1230
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.83524227142334,
      "learning_rate": 4.38e-05,
      "loss": 3.4109,
      "step": 1240
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.23714542388916,
      "learning_rate": 4.375e-05,
      "loss": 3.3678,
      "step": 1250
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.461919784545898,
      "learning_rate": 4.3700000000000005e-05,
      "loss": 3.5971,
      "step": 1260
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.532670021057129,
      "learning_rate": 4.3650000000000004e-05,
      "loss": 3.4307,
      "step": 1270
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.425016403198242,
      "learning_rate": 4.36e-05,
      "loss": 3.5539,
      "step": 1280
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.59865665435791,
      "learning_rate": 4.355e-05,
      "loss": 3.476,
      "step": 1290
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.052870750427246,
      "learning_rate": 4.35e-05,
      "loss": 3.2287,
      "step": 1300
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.74551010131836,
      "learning_rate": 4.345e-05,
      "loss": 3.0867,
      "step": 1310
    },
    {
      "epoch": 0.01,
      "grad_norm": 16.760269165039062,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 3.2676,
      "step": 1320
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.876739501953125,
      "learning_rate": 4.335e-05,
      "loss": 3.4312,
      "step": 1330
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.276247024536133,
      "learning_rate": 4.33e-05,
      "loss": 3.3773,
      "step": 1340
    },
    {
      "epoch": 0.01,
      "grad_norm": 12.288196563720703,
      "learning_rate": 4.325e-05,
      "loss": 3.6613,
      "step": 1350
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.416265487670898,
      "learning_rate": 4.32e-05,
      "loss": 3.1141,
      "step": 1360
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.246076583862305,
      "learning_rate": 4.315e-05,
      "loss": 3.2662,
      "step": 1370
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.177488327026367,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 3.5521,
      "step": 1380
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.613675117492676,
      "learning_rate": 4.305e-05,
      "loss": 3.4971,
      "step": 1390
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.8762845993042,
      "learning_rate": 4.3e-05,
      "loss": 3.2201,
      "step": 1400
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.955082893371582,
      "learning_rate": 4.295e-05,
      "loss": 3.659,
      "step": 1410
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.549444198608398,
      "learning_rate": 4.29e-05,
      "loss": 3.3666,
      "step": 1420
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.217556953430176,
      "learning_rate": 4.285e-05,
      "loss": 3.4301,
      "step": 1430
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.047078132629395,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 3.4949,
      "step": 1440
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.479608535766602,
      "learning_rate": 4.275e-05,
      "loss": 3.4939,
      "step": 1450
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.6846284866333,
      "learning_rate": 4.27e-05,
      "loss": 3.1838,
      "step": 1460
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.289307594299316,
      "learning_rate": 4.265e-05,
      "loss": 3.2002,
      "step": 1470
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.521158218383789,
      "learning_rate": 4.26e-05,
      "loss": 3.0475,
      "step": 1480
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.82552433013916,
      "learning_rate": 4.2550000000000004e-05,
      "loss": 3.4352,
      "step": 1490
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.147815704345703,
      "learning_rate": 4.25e-05,
      "loss": 3.3557,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "eval_bleu-4": 0.03209362283471586,
      "eval_rouge-1": 28.382709999999996,
      "eval_rouge-2": 5.846268,
      "eval_rouge-l": 21.872766,
      "eval_runtime": 85.684,
      "eval_samples_per_second": 0.584,
      "eval_steps_per_second": 0.082,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.041258811950684,
      "learning_rate": 4.245e-05,
      "loss": 3.3332,
      "step": 1510
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.350884437561035,
      "learning_rate": 4.24e-05,
      "loss": 3.4891,
      "step": 1520
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.739027976989746,
      "learning_rate": 4.235e-05,
      "loss": 3.201,
      "step": 1530
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.585443496704102,
      "learning_rate": 4.23e-05,
      "loss": 3.4818,
      "step": 1540
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.01412296295166,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 3.6182,
      "step": 1550
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.034061431884766,
      "learning_rate": 4.22e-05,
      "loss": 3.3859,
      "step": 1560
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.23167896270752,
      "learning_rate": 4.215e-05,
      "loss": 3.3641,
      "step": 1570
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.058780670166016,
      "learning_rate": 4.21e-05,
      "loss": 3.3885,
      "step": 1580
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.089981079101562,
      "learning_rate": 4.205e-05,
      "loss": 3.4312,
      "step": 1590
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.11117172241211,
      "learning_rate": 4.2e-05,
      "loss": 3.2967,
      "step": 1600
    },
    {
      "epoch": 0.01,
      "grad_norm": 15.907118797302246,
      "learning_rate": 4.195e-05,
      "loss": 3.6451,
      "step": 1610
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.087749481201172,
      "learning_rate": 4.19e-05,
      "loss": 3.3939,
      "step": 1620
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.007620811462402,
      "learning_rate": 4.185e-05,
      "loss": 3.6316,
      "step": 1630
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.772307395935059,
      "learning_rate": 4.18e-05,
      "loss": 3.5762,
      "step": 1640
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.805925369262695,
      "learning_rate": 4.175e-05,
      "loss": 3.2326,
      "step": 1650
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.871427536010742,
      "learning_rate": 4.17e-05,
      "loss": 3.2799,
      "step": 1660
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.504363059997559,
      "learning_rate": 4.165e-05,
      "loss": 3.351,
      "step": 1670
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.381000518798828,
      "learning_rate": 4.16e-05,
      "loss": 3.701,
      "step": 1680
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.093770980834961,
      "learning_rate": 4.155e-05,
      "loss": 3.3303,
      "step": 1690
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.4033842086792,
      "learning_rate": 4.15e-05,
      "loss": 3.5207,
      "step": 1700
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.817499160766602,
      "learning_rate": 4.145e-05,
      "loss": 3.5449,
      "step": 1710
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.626297950744629,
      "learning_rate": 4.14e-05,
      "loss": 3.5764,
      "step": 1720
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.785294532775879,
      "learning_rate": 4.135e-05,
      "loss": 3.2035,
      "step": 1730
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.678059577941895,
      "learning_rate": 4.13e-05,
      "loss": 3.2604,
      "step": 1740
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.385030746459961,
      "learning_rate": 4.125e-05,
      "loss": 3.2031,
      "step": 1750
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.228971481323242,
      "learning_rate": 4.12e-05,
      "loss": 3.4055,
      "step": 1760
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.477700233459473,
      "learning_rate": 4.115e-05,
      "loss": 3.049,
      "step": 1770
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.422384262084961,
      "learning_rate": 4.11e-05,
      "loss": 3.2236,
      "step": 1780
    },
    {
      "epoch": 0.02,
      "grad_norm": 16.437288284301758,
      "learning_rate": 4.105e-05,
      "loss": 3.1879,
      "step": 1790
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.1360445022583,
      "learning_rate": 4.1e-05,
      "loss": 3.5502,
      "step": 1800
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.127178192138672,
      "learning_rate": 4.095e-05,
      "loss": 3.2891,
      "step": 1810
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.72115707397461,
      "learning_rate": 4.09e-05,
      "loss": 3.2053,
      "step": 1820
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.666509628295898,
      "learning_rate": 4.085e-05,
      "loss": 3.1602,
      "step": 1830
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.372678756713867,
      "learning_rate": 4.08e-05,
      "loss": 3.3654,
      "step": 1840
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.497004508972168,
      "learning_rate": 4.075e-05,
      "loss": 3.4699,
      "step": 1850
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.506414413452148,
      "learning_rate": 4.07e-05,
      "loss": 3.4875,
      "step": 1860
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.270878791809082,
      "learning_rate": 4.065e-05,
      "loss": 3.2307,
      "step": 1870
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.194282531738281,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 3.5316,
      "step": 1880
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.718878746032715,
      "learning_rate": 4.055e-05,
      "loss": 3.3678,
      "step": 1890
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.77054214477539,
      "learning_rate": 4.05e-05,
      "loss": 3.1441,
      "step": 1900
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.83504867553711,
      "learning_rate": 4.045000000000001e-05,
      "loss": 3.2686,
      "step": 1910
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.61648941040039,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 3.474,
      "step": 1920
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.392048835754395,
      "learning_rate": 4.0350000000000005e-05,
      "loss": 3.1924,
      "step": 1930
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.501655578613281,
      "learning_rate": 4.0300000000000004e-05,
      "loss": 3.5234,
      "step": 1940
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.747188568115234,
      "learning_rate": 4.025e-05,
      "loss": 3.0121,
      "step": 1950
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.52373218536377,
      "learning_rate": 4.02e-05,
      "loss": 3.5033,
      "step": 1960
    },
    {
      "epoch": 0.02,
      "grad_norm": 14.471843719482422,
      "learning_rate": 4.015000000000001e-05,
      "loss": 3.4461,
      "step": 1970
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.242157936096191,
      "learning_rate": 4.0100000000000006e-05,
      "loss": 3.6908,
      "step": 1980
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.260986328125,
      "learning_rate": 4.0050000000000004e-05,
      "loss": 3.4654,
      "step": 1990
    },
    {
      "epoch": 0.02,
      "grad_norm": 29.855594635009766,
      "learning_rate": 4e-05,
      "loss": 3.2293,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "eval_bleu-4": 0.035642562115467104,
      "eval_rouge-1": 32.139672,
      "eval_rouge-2": 6.429436000000001,
      "eval_rouge-l": 23.979604,
      "eval_runtime": 47.3157,
      "eval_samples_per_second": 1.057,
      "eval_steps_per_second": 0.148,
      "step": 2000
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.64411735534668,
      "learning_rate": 3.995e-05,
      "loss": 3.1684,
      "step": 2010
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.41685962677002,
      "learning_rate": 3.99e-05,
      "loss": 3.3252,
      "step": 2020
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.713723182678223,
      "learning_rate": 3.9850000000000006e-05,
      "loss": 3.2691,
      "step": 2030
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.702967643737793,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 3.185,
      "step": 2040
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.404205322265625,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 3.308,
      "step": 2050
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.064579010009766,
      "learning_rate": 3.97e-05,
      "loss": 3.5975,
      "step": 2060
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.871444702148438,
      "learning_rate": 3.965e-05,
      "loss": 3.3873,
      "step": 2070
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.78015422821045,
      "learning_rate": 3.960000000000001e-05,
      "loss": 3.4771,
      "step": 2080
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.020157814025879,
      "learning_rate": 3.9550000000000006e-05,
      "loss": 3.5486,
      "step": 2090
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.86107063293457,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.5141,
      "step": 2100
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.288725852966309,
      "learning_rate": 3.9450000000000003e-05,
      "loss": 3.4662,
      "step": 2110
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.992423057556152,
      "learning_rate": 3.94e-05,
      "loss": 3.2207,
      "step": 2120
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.457566261291504,
      "learning_rate": 3.935e-05,
      "loss": 3.2348,
      "step": 2130
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.062234878540039,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 3.4012,
      "step": 2140
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.547083854675293,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 3.3896,
      "step": 2150
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.624648094177246,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 3.3338,
      "step": 2160
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.787696838378906,
      "learning_rate": 3.915e-05,
      "loss": 3.2854,
      "step": 2170
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.990485191345215,
      "learning_rate": 3.91e-05,
      "loss": 3.7219,
      "step": 2180
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.496782302856445,
      "learning_rate": 3.905e-05,
      "loss": 3.3637,
      "step": 2190
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.235452651977539,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.2295,
      "step": 2200
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.934860229492188,
      "learning_rate": 3.8950000000000005e-05,
      "loss": 3.548,
      "step": 2210
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.582289695739746,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 3.5125,
      "step": 2220
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.548555374145508,
      "learning_rate": 3.885e-05,
      "loss": 3.507,
      "step": 2230
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.709831237792969,
      "learning_rate": 3.88e-05,
      "loss": 3.5781,
      "step": 2240
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.900981903076172,
      "learning_rate": 3.875e-05,
      "loss": 3.4939,
      "step": 2250
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.594334602355957,
      "learning_rate": 3.8700000000000006e-05,
      "loss": 3.3527,
      "step": 2260
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.878876686096191,
      "learning_rate": 3.8650000000000004e-05,
      "loss": 3.4508,
      "step": 2270
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.185526847839355,
      "learning_rate": 3.86e-05,
      "loss": 3.3918,
      "step": 2280
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.304021835327148,
      "learning_rate": 3.855e-05,
      "loss": 3.1389,
      "step": 2290
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.648932456970215,
      "learning_rate": 3.85e-05,
      "loss": 3.3281,
      "step": 2300
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.463224411010742,
      "learning_rate": 3.845e-05,
      "loss": 3.1867,
      "step": 2310
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.26512336730957,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 3.3953,
      "step": 2320
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.845187187194824,
      "learning_rate": 3.8350000000000004e-05,
      "loss": 3.1078,
      "step": 2330
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.211419105529785,
      "learning_rate": 3.83e-05,
      "loss": 3.1506,
      "step": 2340
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.818782806396484,
      "learning_rate": 3.825e-05,
      "loss": 3.5277,
      "step": 2350
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.945054054260254,
      "learning_rate": 3.82e-05,
      "loss": 3.3852,
      "step": 2360
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.257853507995605,
      "learning_rate": 3.8150000000000006e-05,
      "loss": 3.3447,
      "step": 2370
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.494058609008789,
      "learning_rate": 3.8100000000000005e-05,
      "loss": 3.4275,
      "step": 2380
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.146615028381348,
      "learning_rate": 3.805e-05,
      "loss": 3.3535,
      "step": 2390
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.346037864685059,
      "learning_rate": 3.8e-05,
      "loss": 3.3891,
      "step": 2400
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.417096138000488,
      "learning_rate": 3.795e-05,
      "loss": 3.3998,
      "step": 2410
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.892531394958496,
      "learning_rate": 3.79e-05,
      "loss": 3.3256,
      "step": 2420
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.228937149047852,
      "learning_rate": 3.7850000000000005e-05,
      "loss": 3.1801,
      "step": 2430
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.747912406921387,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 3.3629,
      "step": 2440
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.806979179382324,
      "learning_rate": 3.775e-05,
      "loss": 3.2432,
      "step": 2450
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.296894073486328,
      "learning_rate": 3.77e-05,
      "loss": 3.177,
      "step": 2460
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.569808006286621,
      "learning_rate": 3.765e-05,
      "loss": 3.0861,
      "step": 2470
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.095311164855957,
      "learning_rate": 3.76e-05,
      "loss": 3.7883,
      "step": 2480
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.587240219116211,
      "learning_rate": 3.7550000000000005e-05,
      "loss": 3.218,
      "step": 2490
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.370443344116211,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 3.3533,
      "step": 2500
    },
    {
      "epoch": 0.02,
      "eval_bleu-4": 0.034677325867214115,
      "eval_rouge-1": 30.109195999999997,
      "eval_rouge-2": 6.406076,
      "eval_rouge-l": 23.354115999999998,
      "eval_runtime": 61.4277,
      "eval_samples_per_second": 0.814,
      "eval_steps_per_second": 0.114,
      "step": 2500
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.48072338104248,
      "learning_rate": 3.745e-05,
      "loss": 3.3422,
      "step": 2510
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.164567947387695,
      "learning_rate": 3.74e-05,
      "loss": 3.4271,
      "step": 2520
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.775014877319336,
      "learning_rate": 3.735e-05,
      "loss": 3.2139,
      "step": 2530
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.353065490722656,
      "learning_rate": 3.73e-05,
      "loss": 3.2162,
      "step": 2540
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.355256080627441,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 3.5787,
      "step": 2550
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.762782096862793,
      "learning_rate": 3.72e-05,
      "loss": 3.4805,
      "step": 2560
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.540831565856934,
      "learning_rate": 3.715e-05,
      "loss": 3.359,
      "step": 2570
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.469523429870605,
      "learning_rate": 3.71e-05,
      "loss": 3.3965,
      "step": 2580
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.191823959350586,
      "learning_rate": 3.705e-05,
      "loss": 3.4566,
      "step": 2590
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.021151542663574,
      "learning_rate": 3.7e-05,
      "loss": 3.527,
      "step": 2600
    },
    {
      "epoch": 0.02,
      "grad_norm": 15.414324760437012,
      "learning_rate": 3.6950000000000004e-05,
      "loss": 3.2963,
      "step": 2610
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.451318740844727,
      "learning_rate": 3.69e-05,
      "loss": 3.3316,
      "step": 2620
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.350886344909668,
      "learning_rate": 3.685e-05,
      "loss": 3.4705,
      "step": 2630
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.1199951171875,
      "learning_rate": 3.68e-05,
      "loss": 3.3033,
      "step": 2640
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.564385414123535,
      "learning_rate": 3.675e-05,
      "loss": 3.6057,
      "step": 2650
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.0095796585083,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 3.3543,
      "step": 2660
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.732369422912598,
      "learning_rate": 3.665e-05,
      "loss": 3.475,
      "step": 2670
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.113054275512695,
      "learning_rate": 3.66e-05,
      "loss": 3.2062,
      "step": 2680
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.003042221069336,
      "learning_rate": 3.655e-05,
      "loss": 3.5215,
      "step": 2690
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.855223655700684,
      "learning_rate": 3.65e-05,
      "loss": 3.1143,
      "step": 2700
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.624430656433105,
      "learning_rate": 3.645e-05,
      "loss": 3.0299,
      "step": 2710
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.56842041015625,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 3.091,
      "step": 2720
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.906610488891602,
      "learning_rate": 3.635e-05,
      "loss": 3.2803,
      "step": 2730
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.228180885314941,
      "learning_rate": 3.63e-05,
      "loss": 3.3414,
      "step": 2740
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.361982345581055,
      "learning_rate": 3.625e-05,
      "loss": 3.1369,
      "step": 2750
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.452404022216797,
      "learning_rate": 3.62e-05,
      "loss": 3.3383,
      "step": 2760
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.107748985290527,
      "learning_rate": 3.615e-05,
      "loss": 3.3762,
      "step": 2770
    },
    {
      "epoch": 0.02,
      "grad_norm": 13.176302909851074,
      "learning_rate": 3.61e-05,
      "loss": 3.1279,
      "step": 2780
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.150382995605469,
      "learning_rate": 3.605e-05,
      "loss": 3.3813,
      "step": 2790
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.598420143127441,
      "learning_rate": 3.6e-05,
      "loss": 3.2709,
      "step": 2800
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.309087753295898,
      "learning_rate": 3.595e-05,
      "loss": 3.5236,
      "step": 2810
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.357026100158691,
      "learning_rate": 3.59e-05,
      "loss": 3.393,
      "step": 2820
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.027480125427246,
      "learning_rate": 3.585e-05,
      "loss": 3.3154,
      "step": 2830
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.728893280029297,
      "learning_rate": 3.58e-05,
      "loss": 3.21,
      "step": 2840
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.884882926940918,
      "learning_rate": 3.575e-05,
      "loss": 3.3523,
      "step": 2850
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.955188751220703,
      "learning_rate": 3.57e-05,
      "loss": 3.0506,
      "step": 2860
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.977957725524902,
      "learning_rate": 3.565e-05,
      "loss": 3.7721,
      "step": 2870
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.925981521606445,
      "learning_rate": 3.56e-05,
      "loss": 3.4973,
      "step": 2880
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.889359474182129,
      "learning_rate": 3.555e-05,
      "loss": 3.0768,
      "step": 2890
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.336980819702148,
      "learning_rate": 3.55e-05,
      "loss": 3.2912,
      "step": 2900
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.094005584716797,
      "learning_rate": 3.545e-05,
      "loss": 3.2236,
      "step": 2910
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.37882137298584,
      "learning_rate": 3.54e-05,
      "loss": 2.999,
      "step": 2920
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.340954780578613,
      "learning_rate": 3.535e-05,
      "loss": 3.685,
      "step": 2930
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.34754753112793,
      "learning_rate": 3.53e-05,
      "loss": 3.4229,
      "step": 2940
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.841819763183594,
      "learning_rate": 3.525e-05,
      "loss": 3.3553,
      "step": 2950
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.785228729248047,
      "learning_rate": 3.52e-05,
      "loss": 3.2904,
      "step": 2960
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.218910217285156,
      "learning_rate": 3.515e-05,
      "loss": 3.3207,
      "step": 2970
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.929184913635254,
      "learning_rate": 3.51e-05,
      "loss": 3.3383,
      "step": 2980
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.152631759643555,
      "learning_rate": 3.505e-05,
      "loss": 3.2563,
      "step": 2990
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.601692199707031,
      "learning_rate": 3.5e-05,
      "loss": 3.165,
      "step": 3000
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.038035725771366914,
      "eval_rouge-1": 31.158439999999995,
      "eval_rouge-2": 6.703902,
      "eval_rouge-l": 23.182489999999998,
      "eval_runtime": 77.9661,
      "eval_samples_per_second": 0.641,
      "eval_steps_per_second": 0.09,
      "step": 3000
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.892816543579102,
      "learning_rate": 3.495e-05,
      "loss": 3.2104,
      "step": 3010
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.141682624816895,
      "learning_rate": 3.49e-05,
      "loss": 3.1957,
      "step": 3020
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.360748291015625,
      "learning_rate": 3.485e-05,
      "loss": 3.6008,
      "step": 3030
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.203340530395508,
      "learning_rate": 3.48e-05,
      "loss": 3.4246,
      "step": 3040
    },
    {
      "epoch": 0.03,
      "grad_norm": 7.543859004974365,
      "learning_rate": 3.475e-05,
      "loss": 3.2045,
      "step": 3050
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.079961776733398,
      "learning_rate": 3.4699999999999996e-05,
      "loss": 3.6236,
      "step": 3060
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.126371383666992,
      "learning_rate": 3.465e-05,
      "loss": 3.4793,
      "step": 3070
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.83140754699707,
      "learning_rate": 3.46e-05,
      "loss": 3.6615,
      "step": 3080
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.62700366973877,
      "learning_rate": 3.455e-05,
      "loss": 3.3252,
      "step": 3090
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.699382781982422,
      "learning_rate": 3.45e-05,
      "loss": 3.4873,
      "step": 3100
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.278219223022461,
      "learning_rate": 3.445e-05,
      "loss": 3.3281,
      "step": 3110
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.061676979064941,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 3.2154,
      "step": 3120
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.97636890411377,
      "learning_rate": 3.435e-05,
      "loss": 3.2227,
      "step": 3130
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.448651313781738,
      "learning_rate": 3.430000000000001e-05,
      "loss": 3.3244,
      "step": 3140
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.22818660736084,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 3.1414,
      "step": 3150
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.561042785644531,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 3.1418,
      "step": 3160
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.621500968933105,
      "learning_rate": 3.415e-05,
      "loss": 3.4996,
      "step": 3170
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.359968185424805,
      "learning_rate": 3.41e-05,
      "loss": 3.4164,
      "step": 3180
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.770748138427734,
      "learning_rate": 3.405e-05,
      "loss": 3.5125,
      "step": 3190
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.172327995300293,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.4428,
      "step": 3200
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.625439643859863,
      "learning_rate": 3.3950000000000005e-05,
      "loss": 3.3158,
      "step": 3210
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.846794128417969,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 3.0873,
      "step": 3220
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.845867156982422,
      "learning_rate": 3.385e-05,
      "loss": 3.076,
      "step": 3230
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.628679275512695,
      "learning_rate": 3.38e-05,
      "loss": 3.2129,
      "step": 3240
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.768106460571289,
      "learning_rate": 3.375000000000001e-05,
      "loss": 3.1096,
      "step": 3250
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.532544136047363,
      "learning_rate": 3.3700000000000006e-05,
      "loss": 3.0945,
      "step": 3260
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.03429126739502,
      "learning_rate": 3.3650000000000005e-05,
      "loss": 3.241,
      "step": 3270
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.546826362609863,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 3.4338,
      "step": 3280
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.641120910644531,
      "learning_rate": 3.355e-05,
      "loss": 3.3049,
      "step": 3290
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.057117462158203,
      "learning_rate": 3.35e-05,
      "loss": 3.2906,
      "step": 3300
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.22967529296875,
      "learning_rate": 3.345000000000001e-05,
      "loss": 3.5328,
      "step": 3310
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.539103507995605,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 3.1363,
      "step": 3320
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.659783363342285,
      "learning_rate": 3.3350000000000004e-05,
      "loss": 3.149,
      "step": 3330
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.014775276184082,
      "learning_rate": 3.33e-05,
      "loss": 3.4056,
      "step": 3340
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.164631843566895,
      "learning_rate": 3.325e-05,
      "loss": 3.2756,
      "step": 3350
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.649194717407227,
      "learning_rate": 3.32e-05,
      "loss": 3.4311,
      "step": 3360
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.035422325134277,
      "learning_rate": 3.3150000000000006e-05,
      "loss": 3.4186,
      "step": 3370
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.270394325256348,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 3.2645,
      "step": 3380
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.362714767456055,
      "learning_rate": 3.3050000000000004e-05,
      "loss": 3.1512,
      "step": 3390
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.117783546447754,
      "learning_rate": 3.3e-05,
      "loss": 3.573,
      "step": 3400
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.978540420532227,
      "learning_rate": 3.295e-05,
      "loss": 3.3807,
      "step": 3410
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.786909103393555,
      "learning_rate": 3.29e-05,
      "loss": 3.6223,
      "step": 3420
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.266925811767578,
      "learning_rate": 3.2850000000000006e-05,
      "loss": 3.3967,
      "step": 3430
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.253079414367676,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 3.5531,
      "step": 3440
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.417954444885254,
      "learning_rate": 3.275e-05,
      "loss": 3.31,
      "step": 3450
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.261219024658203,
      "learning_rate": 3.27e-05,
      "loss": 3.1713,
      "step": 3460
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.890206336975098,
      "learning_rate": 3.265e-05,
      "loss": 2.9402,
      "step": 3470
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.150362014770508,
      "learning_rate": 3.26e-05,
      "loss": 3.1984,
      "step": 3480
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.803203582763672,
      "learning_rate": 3.2550000000000005e-05,
      "loss": 3.3393,
      "step": 3490
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.925819396972656,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 3.3299,
      "step": 3500
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.042090917953550085,
      "eval_rouge-1": 32.02163,
      "eval_rouge-2": 7.492608000000001,
      "eval_rouge-l": 24.17475,
      "eval_runtime": 61.6242,
      "eval_samples_per_second": 0.811,
      "eval_steps_per_second": 0.114,
      "step": 3500
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.458600044250488,
      "learning_rate": 3.245e-05,
      "loss": 3.5012,
      "step": 3510
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.74829387664795,
      "learning_rate": 3.24e-05,
      "loss": 3.2758,
      "step": 3520
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.427791595458984,
      "learning_rate": 3.235e-05,
      "loss": 3.3898,
      "step": 3530
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.65322494506836,
      "learning_rate": 3.2300000000000006e-05,
      "loss": 3.424,
      "step": 3540
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.125337600708008,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 3.2172,
      "step": 3550
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.680099487304688,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 3.2541,
      "step": 3560
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.290133476257324,
      "learning_rate": 3.215e-05,
      "loss": 3.0919,
      "step": 3570
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.733685493469238,
      "learning_rate": 3.21e-05,
      "loss": 3.2037,
      "step": 3580
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.577247619628906,
      "learning_rate": 3.205e-05,
      "loss": 3.0973,
      "step": 3590
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.604267120361328,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.2461,
      "step": 3600
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.05720329284668,
      "learning_rate": 3.1950000000000004e-05,
      "loss": 3.0861,
      "step": 3610
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.43173885345459,
      "learning_rate": 3.19e-05,
      "loss": 3.6033,
      "step": 3620
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.136457443237305,
      "learning_rate": 3.185e-05,
      "loss": 3.248,
      "step": 3630
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.222434997558594,
      "learning_rate": 3.18e-05,
      "loss": 3.366,
      "step": 3640
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.069679260253906,
      "learning_rate": 3.175e-05,
      "loss": 3.3883,
      "step": 3650
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.696747779846191,
      "learning_rate": 3.1700000000000005e-05,
      "loss": 2.9871,
      "step": 3660
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.261747360229492,
      "learning_rate": 3.1650000000000004e-05,
      "loss": 3.4588,
      "step": 3670
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.241353034973145,
      "learning_rate": 3.16e-05,
      "loss": 3.1883,
      "step": 3680
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.84470272064209,
      "learning_rate": 3.155e-05,
      "loss": 3.5057,
      "step": 3690
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.331730842590332,
      "learning_rate": 3.15e-05,
      "loss": 3.3449,
      "step": 3700
    },
    {
      "epoch": 0.03,
      "grad_norm": 14.750328063964844,
      "learning_rate": 3.145e-05,
      "loss": 3.1004,
      "step": 3710
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.101184844970703,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 3.36,
      "step": 3720
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.743490219116211,
      "learning_rate": 3.135e-05,
      "loss": 3.5162,
      "step": 3730
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.708028793334961,
      "learning_rate": 3.13e-05,
      "loss": 3.3969,
      "step": 3740
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.446495056152344,
      "learning_rate": 3.125e-05,
      "loss": 3.3285,
      "step": 3750
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.5759859085083,
      "learning_rate": 3.12e-05,
      "loss": 3.5229,
      "step": 3760
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.542906761169434,
      "learning_rate": 3.115e-05,
      "loss": 3.3883,
      "step": 3770
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.806554794311523,
      "learning_rate": 3.1100000000000004e-05,
      "loss": 3.3361,
      "step": 3780
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.029182434082031,
      "learning_rate": 3.105e-05,
      "loss": 3.2059,
      "step": 3790
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.685840606689453,
      "learning_rate": 3.1e-05,
      "loss": 3.1797,
      "step": 3800
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.021096229553223,
      "learning_rate": 3.095e-05,
      "loss": 3.4645,
      "step": 3810
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.834603309631348,
      "learning_rate": 3.09e-05,
      "loss": 3.2588,
      "step": 3820
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.98598861694336,
      "learning_rate": 3.0850000000000004e-05,
      "loss": 3.2779,
      "step": 3830
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.334939002990723,
      "learning_rate": 3.08e-05,
      "loss": 3.2502,
      "step": 3840
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.648622512817383,
      "learning_rate": 3.075e-05,
      "loss": 3.3127,
      "step": 3850
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.686485290527344,
      "learning_rate": 3.07e-05,
      "loss": 3.4748,
      "step": 3860
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.485685348510742,
      "learning_rate": 3.065e-05,
      "loss": 3.3861,
      "step": 3870
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.842606544494629,
      "learning_rate": 3.06e-05,
      "loss": 3.3902,
      "step": 3880
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.815068244934082,
      "learning_rate": 3.0550000000000004e-05,
      "loss": 3.1037,
      "step": 3890
    },
    {
      "epoch": 0.03,
      "grad_norm": 14.353920936584473,
      "learning_rate": 3.05e-05,
      "loss": 3.0809,
      "step": 3900
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.676641464233398,
      "learning_rate": 3.045e-05,
      "loss": 3.393,
      "step": 3910
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.339156150817871,
      "learning_rate": 3.04e-05,
      "loss": 3.0754,
      "step": 3920
    },
    {
      "epoch": 0.03,
      "grad_norm": 13.214555740356445,
      "learning_rate": 3.035e-05,
      "loss": 3.1865,
      "step": 3930
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.76211929321289,
      "learning_rate": 3.03e-05,
      "loss": 3.3902,
      "step": 3940
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.04698657989502,
      "learning_rate": 3.025e-05,
      "loss": 3.1664,
      "step": 3950
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.393106460571289,
      "learning_rate": 3.02e-05,
      "loss": 3.5859,
      "step": 3960
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.482322692871094,
      "learning_rate": 3.015e-05,
      "loss": 3.3893,
      "step": 3970
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.144529342651367,
      "learning_rate": 3.01e-05,
      "loss": 3.2309,
      "step": 3980
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.678370475769043,
      "learning_rate": 3.0050000000000002e-05,
      "loss": 3.1211,
      "step": 3990
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.712424278259277,
      "learning_rate": 3e-05,
      "loss": 3.3115,
      "step": 4000
    },
    {
      "epoch": 0.03,
      "eval_bleu-4": 0.0429188899463258,
      "eval_rouge-1": 31.627883999999998,
      "eval_rouge-2": 7.376944,
      "eval_rouge-l": 24.987028,
      "eval_runtime": 45.9454,
      "eval_samples_per_second": 1.088,
      "eval_steps_per_second": 0.152,
      "step": 4000
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.519393920898438,
      "learning_rate": 2.995e-05,
      "loss": 3.6043,
      "step": 4010
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.543929100036621,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 3.2967,
      "step": 4020
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.612277030944824,
      "learning_rate": 2.985e-05,
      "loss": 3.1666,
      "step": 4030
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.148177146911621,
      "learning_rate": 2.98e-05,
      "loss": 3.3381,
      "step": 4040
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.613458633422852,
      "learning_rate": 2.975e-05,
      "loss": 3.0613,
      "step": 4050
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.926481246948242,
      "learning_rate": 2.97e-05,
      "loss": 3.4324,
      "step": 4060
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.787467002868652,
      "learning_rate": 2.965e-05,
      "loss": 3.4021,
      "step": 4070
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.162117958068848,
      "learning_rate": 2.96e-05,
      "loss": 3.3631,
      "step": 4080
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.80903434753418,
      "learning_rate": 2.955e-05,
      "loss": 3.1252,
      "step": 4090
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.461817741394043,
      "learning_rate": 2.95e-05,
      "loss": 3.7775,
      "step": 4100
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.131025314331055,
      "learning_rate": 2.945e-05,
      "loss": 3.4328,
      "step": 4110
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.666522979736328,
      "learning_rate": 2.94e-05,
      "loss": 3.7982,
      "step": 4120
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.76442813873291,
      "learning_rate": 2.935e-05,
      "loss": 3.3777,
      "step": 4130
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.089797019958496,
      "learning_rate": 2.93e-05,
      "loss": 3.3297,
      "step": 4140
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.657673835754395,
      "learning_rate": 2.925e-05,
      "loss": 3.226,
      "step": 4150
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.145931243896484,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 3.3357,
      "step": 4160
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.212035179138184,
      "learning_rate": 2.915e-05,
      "loss": 3.3936,
      "step": 4170
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.920282363891602,
      "learning_rate": 2.91e-05,
      "loss": 3.4061,
      "step": 4180
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.597085952758789,
      "learning_rate": 2.9049999999999998e-05,
      "loss": 3.1211,
      "step": 4190
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.900251388549805,
      "learning_rate": 2.9e-05,
      "loss": 3.1314,
      "step": 4200
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.974812507629395,
      "learning_rate": 2.895e-05,
      "loss": 3.134,
      "step": 4210
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.485151290893555,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 3.1083,
      "step": 4220
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.684578895568848,
      "learning_rate": 2.885e-05,
      "loss": 3.3225,
      "step": 4230
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.275200843811035,
      "learning_rate": 2.88e-05,
      "loss": 3.3137,
      "step": 4240
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.891529083251953,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 3.3205,
      "step": 4250
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.309560775756836,
      "learning_rate": 2.87e-05,
      "loss": 3.4561,
      "step": 4260
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.220866203308105,
      "learning_rate": 2.865e-05,
      "loss": 2.9748,
      "step": 4270
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.65316104888916,
      "learning_rate": 2.86e-05,
      "loss": 3.1586,
      "step": 4280
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.209736824035645,
      "learning_rate": 2.855e-05,
      "loss": 3.2547,
      "step": 4290
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.18117904663086,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 3.3236,
      "step": 4300
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.588610649108887,
      "learning_rate": 2.845e-05,
      "loss": 3.4115,
      "step": 4310
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.703948020935059,
      "learning_rate": 2.84e-05,
      "loss": 3.3477,
      "step": 4320
    },
    {
      "epoch": 0.04,
      "grad_norm": 14.421317100524902,
      "learning_rate": 2.8349999999999998e-05,
      "loss": 3.6719,
      "step": 4330
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.303897857666016,
      "learning_rate": 2.83e-05,
      "loss": 3.2268,
      "step": 4340
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.823995590209961,
      "learning_rate": 2.825e-05,
      "loss": 3.4197,
      "step": 4350
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.237606048583984,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 3.3217,
      "step": 4360
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.127302169799805,
      "learning_rate": 2.815e-05,
      "loss": 3.3836,
      "step": 4370
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.759710311889648,
      "learning_rate": 2.8100000000000005e-05,
      "loss": 3.4492,
      "step": 4380
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.217999458312988,
      "learning_rate": 2.8050000000000004e-05,
      "loss": 3.2668,
      "step": 4390
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.37192440032959,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.1986,
      "step": 4400
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.2358980178833,
      "learning_rate": 2.7950000000000005e-05,
      "loss": 3.2064,
      "step": 4410
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.01599407196045,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 3.1557,
      "step": 4420
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.790188789367676,
      "learning_rate": 2.7850000000000003e-05,
      "loss": 3.2432,
      "step": 4430
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.127519607543945,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 3.1826,
      "step": 4440
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.516033172607422,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 3.1914,
      "step": 4450
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.932005882263184,
      "learning_rate": 2.7700000000000002e-05,
      "loss": 3.3283,
      "step": 4460
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.118576049804688,
      "learning_rate": 2.7650000000000005e-05,
      "loss": 3.533,
      "step": 4470
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.371685981750488,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 3.6107,
      "step": 4480
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.069318771362305,
      "learning_rate": 2.7550000000000002e-05,
      "loss": 3.3971,
      "step": 4490
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.748373031616211,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 3.0307,
      "step": 4500
    },
    {
      "epoch": 0.04,
      "eval_bleu-4": 0.04131825326758753,
      "eval_rouge-1": 31.475434,
      "eval_rouge-2": 7.45051,
      "eval_rouge-l": 24.85289,
      "eval_runtime": 61.1456,
      "eval_samples_per_second": 0.818,
      "eval_steps_per_second": 0.114,
      "step": 4500
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.294732093811035,
      "learning_rate": 2.7450000000000003e-05,
      "loss": 3.4869,
      "step": 4510
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.669816017150879,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 3.3539,
      "step": 4520
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.405659675598145,
      "learning_rate": 2.7350000000000004e-05,
      "loss": 3.1063,
      "step": 4530
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.742300033569336,
      "learning_rate": 2.7300000000000003e-05,
      "loss": 3.3617,
      "step": 4540
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.009248733520508,
      "learning_rate": 2.725e-05,
      "loss": 3.2889,
      "step": 4550
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.841439247131348,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 3.2426,
      "step": 4560
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.083988189697266,
      "learning_rate": 2.7150000000000003e-05,
      "loss": 3.2607,
      "step": 4570
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.091477394104004,
      "learning_rate": 2.7100000000000005e-05,
      "loss": 3.1416,
      "step": 4580
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.331277847290039,
      "learning_rate": 2.7050000000000004e-05,
      "loss": 3.0615,
      "step": 4590
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.840108871459961,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.2469,
      "step": 4600
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.151923179626465,
      "learning_rate": 2.6950000000000005e-05,
      "loss": 3.2165,
      "step": 4610
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.85216999053955,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 3.3301,
      "step": 4620
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.325461387634277,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 3.2266,
      "step": 4630
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.194764137268066,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 3.1412,
      "step": 4640
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.832096099853516,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 3.4207,
      "step": 4650
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.112346649169922,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 3.3102,
      "step": 4660
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.964679718017578,
      "learning_rate": 2.6650000000000004e-05,
      "loss": 3.3328,
      "step": 4670
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.405755043029785,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 3.0666,
      "step": 4680
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.141704559326172,
      "learning_rate": 2.655e-05,
      "loss": 3.3049,
      "step": 4690
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.172533988952637,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 3.2172,
      "step": 4700
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.386609077453613,
      "learning_rate": 2.6450000000000003e-05,
      "loss": 3.6172,
      "step": 4710
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.298002243041992,
      "learning_rate": 2.64e-05,
      "loss": 3.1561,
      "step": 4720
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.226821899414062,
      "learning_rate": 2.6350000000000004e-05,
      "loss": 3.3457,
      "step": 4730
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.435879707336426,
      "learning_rate": 2.6300000000000002e-05,
      "loss": 3.2721,
      "step": 4740
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.396092414855957,
      "learning_rate": 2.625e-05,
      "loss": 3.0912,
      "step": 4750
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.233489990234375,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 3.1557,
      "step": 4760
    },
    {
      "epoch": 0.04,
      "grad_norm": 14.244917869567871,
      "learning_rate": 2.6150000000000002e-05,
      "loss": 3.3152,
      "step": 4770
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.150092124938965,
      "learning_rate": 2.61e-05,
      "loss": 3.1191,
      "step": 4780
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.342606544494629,
      "learning_rate": 2.6050000000000003e-05,
      "loss": 3.3479,
      "step": 4790
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.962018966674805,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.4377,
      "step": 4800
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.71577262878418,
      "learning_rate": 2.595e-05,
      "loss": 3.0928,
      "step": 4810
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.924699783325195,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 3.1352,
      "step": 4820
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.23606014251709,
      "learning_rate": 2.585e-05,
      "loss": 3.134,
      "step": 4830
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.556303977966309,
      "learning_rate": 2.58e-05,
      "loss": 2.9269,
      "step": 4840
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.746788024902344,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 3.1111,
      "step": 4850
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.354571342468262,
      "learning_rate": 2.57e-05,
      "loss": 3.195,
      "step": 4860
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.964025497436523,
      "learning_rate": 2.5650000000000003e-05,
      "loss": 3.6367,
      "step": 4870
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.718265533447266,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 3.0389,
      "step": 4880
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.318218231201172,
      "learning_rate": 2.555e-05,
      "loss": 3.0473,
      "step": 4890
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.208600044250488,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 3.2986,
      "step": 4900
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.293585777282715,
      "learning_rate": 2.5450000000000002e-05,
      "loss": 3.4365,
      "step": 4910
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.979641914367676,
      "learning_rate": 2.54e-05,
      "loss": 3.1771,
      "step": 4920
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.841324806213379,
      "learning_rate": 2.5350000000000003e-05,
      "loss": 3.4643,
      "step": 4930
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.144013404846191,
      "learning_rate": 2.5300000000000002e-05,
      "loss": 3.1928,
      "step": 4940
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.719304084777832,
      "learning_rate": 2.525e-05,
      "loss": 3.1043,
      "step": 4950
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.966647148132324,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 3.3307,
      "step": 4960
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.825407981872559,
      "learning_rate": 2.515e-05,
      "loss": 3.3613,
      "step": 4970
    },
    {
      "epoch": 0.04,
      "grad_norm": 11.388537406921387,
      "learning_rate": 2.51e-05,
      "loss": 3.4369,
      "step": 4980
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.495577812194824,
      "learning_rate": 2.5050000000000002e-05,
      "loss": 3.1915,
      "step": 4990
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.348076820373535,
      "learning_rate": 2.5e-05,
      "loss": 3.2137,
      "step": 5000
    },
    {
      "epoch": 0.04,
      "eval_bleu-4": 0.04192574732096542,
      "eval_rouge-1": 31.527872000000006,
      "eval_rouge-2": 7.127995999999999,
      "eval_rouge-l": 23.397074000000003,
      "eval_runtime": 59.2756,
      "eval_samples_per_second": 0.844,
      "eval_steps_per_second": 0.118,
      "step": 5000
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.718643188476562,
      "learning_rate": 2.495e-05,
      "loss": 3.2361,
      "step": 5010
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.166921615600586,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 3.1678,
      "step": 5020
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.640570640563965,
      "learning_rate": 2.485e-05,
      "loss": 3.0494,
      "step": 5030
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.759356498718262,
      "learning_rate": 2.48e-05,
      "loss": 3.1395,
      "step": 5040
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.462315559387207,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 3.5217,
      "step": 5050
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.41445255279541,
      "learning_rate": 2.47e-05,
      "loss": 3.1547,
      "step": 5060
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.532325744628906,
      "learning_rate": 2.465e-05,
      "loss": 3.2076,
      "step": 5070
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.706774711608887,
      "learning_rate": 2.46e-05,
      "loss": 3.3076,
      "step": 5080
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.92780876159668,
      "learning_rate": 2.455e-05,
      "loss": 3.3922,
      "step": 5090
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.24710464477539,
      "learning_rate": 2.45e-05,
      "loss": 3.0332,
      "step": 5100
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.802216529846191,
      "learning_rate": 2.445e-05,
      "loss": 3.1875,
      "step": 5110
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.872442245483398,
      "learning_rate": 2.44e-05,
      "loss": 3.2664,
      "step": 5120
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.976473808288574,
      "learning_rate": 2.435e-05,
      "loss": 3.2605,
      "step": 5130
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.491878509521484,
      "learning_rate": 2.43e-05,
      "loss": 3.2539,
      "step": 5140
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.478377342224121,
      "learning_rate": 2.425e-05,
      "loss": 3.216,
      "step": 5150
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.243551254272461,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 3.2373,
      "step": 5160
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.472930908203125,
      "learning_rate": 2.415e-05,
      "loss": 3.5066,
      "step": 5170
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.448269844055176,
      "learning_rate": 2.41e-05,
      "loss": 3.318,
      "step": 5180
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.467432975769043,
      "learning_rate": 2.4050000000000002e-05,
      "loss": 3.2297,
      "step": 5190
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.426589012145996,
      "learning_rate": 2.4e-05,
      "loss": 3.2824,
      "step": 5200
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.366423606872559,
      "learning_rate": 2.395e-05,
      "loss": 3.4172,
      "step": 5210
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.281214714050293,
      "learning_rate": 2.39e-05,
      "loss": 3.5762,
      "step": 5220
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.65108871459961,
      "learning_rate": 2.385e-05,
      "loss": 3.2855,
      "step": 5230
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.093677520751953,
      "learning_rate": 2.38e-05,
      "loss": 3.1021,
      "step": 5240
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.410575866699219,
      "learning_rate": 2.375e-05,
      "loss": 3.5285,
      "step": 5250
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.127066612243652,
      "learning_rate": 2.37e-05,
      "loss": 3.1682,
      "step": 5260
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.05966854095459,
      "learning_rate": 2.365e-05,
      "loss": 3.334,
      "step": 5270
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.290390014648438,
      "learning_rate": 2.36e-05,
      "loss": 3.3605,
      "step": 5280
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.125616073608398,
      "learning_rate": 2.355e-05,
      "loss": 3.2602,
      "step": 5290
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.665367126464844,
      "learning_rate": 2.35e-05,
      "loss": 3.368,
      "step": 5300
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.635411262512207,
      "learning_rate": 2.345e-05,
      "loss": 3.2367,
      "step": 5310
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.898097038269043,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 3.2027,
      "step": 5320
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.449397087097168,
      "learning_rate": 2.3350000000000002e-05,
      "loss": 3.1412,
      "step": 5330
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.517755508422852,
      "learning_rate": 2.3300000000000004e-05,
      "loss": 3.124,
      "step": 5340
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.726889610290527,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 3.1313,
      "step": 5350
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.14266586303711,
      "learning_rate": 2.32e-05,
      "loss": 3.2736,
      "step": 5360
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.33634090423584,
      "learning_rate": 2.3150000000000004e-05,
      "loss": 3.274,
      "step": 5370
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.87739086151123,
      "learning_rate": 2.3100000000000002e-05,
      "loss": 3.1361,
      "step": 5380
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.581324577331543,
      "learning_rate": 2.305e-05,
      "loss": 3.2385,
      "step": 5390
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.915895462036133,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.2867,
      "step": 5400
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.18898868560791,
      "learning_rate": 2.2950000000000002e-05,
      "loss": 2.9963,
      "step": 5410
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.492511749267578,
      "learning_rate": 2.29e-05,
      "loss": 3.1084,
      "step": 5420
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.601245880126953,
      "learning_rate": 2.2850000000000003e-05,
      "loss": 3.2338,
      "step": 5430
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.935442924499512,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 3.3381,
      "step": 5440
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.044633865356445,
      "learning_rate": 2.275e-05,
      "loss": 3.4736,
      "step": 5450
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.360029220581055,
      "learning_rate": 2.2700000000000003e-05,
      "loss": 3.4354,
      "step": 5460
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.3706693649292,
      "learning_rate": 2.265e-05,
      "loss": 3.168,
      "step": 5470
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.305421829223633,
      "learning_rate": 2.26e-05,
      "loss": 3.4813,
      "step": 5480
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.781763076782227,
      "learning_rate": 2.2550000000000003e-05,
      "loss": 3.2596,
      "step": 5490
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.600889205932617,
      "learning_rate": 2.25e-05,
      "loss": 3.1844,
      "step": 5500
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.0399214053567692,
      "eval_rouge-1": 32.07194200000001,
      "eval_rouge-2": 7.155114,
      "eval_rouge-l": 23.939592,
      "eval_runtime": 61.5444,
      "eval_samples_per_second": 0.812,
      "eval_steps_per_second": 0.114,
      "step": 5500
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.177248001098633,
      "learning_rate": 2.245e-05,
      "loss": 3.1934,
      "step": 5510
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.627195358276367,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 3.4145,
      "step": 5520
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.74931812286377,
      "learning_rate": 2.235e-05,
      "loss": 3.4959,
      "step": 5530
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.73010540008545,
      "learning_rate": 2.23e-05,
      "loss": 3.1039,
      "step": 5540
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.371138572692871,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 3.4443,
      "step": 5550
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.915680885314941,
      "learning_rate": 2.22e-05,
      "loss": 2.9396,
      "step": 5560
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.946195602416992,
      "learning_rate": 2.215e-05,
      "loss": 3.1896,
      "step": 5570
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.559184074401855,
      "learning_rate": 2.2100000000000002e-05,
      "loss": 3.4408,
      "step": 5580
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.132299423217773,
      "learning_rate": 2.205e-05,
      "loss": 3.3814,
      "step": 5590
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.057705879211426,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.1512,
      "step": 5600
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.126373291015625,
      "learning_rate": 2.195e-05,
      "loss": 3.2717,
      "step": 5610
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.125965118408203,
      "learning_rate": 2.19e-05,
      "loss": 3.1301,
      "step": 5620
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.168200492858887,
      "learning_rate": 2.1850000000000003e-05,
      "loss": 3.1277,
      "step": 5630
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.627287864685059,
      "learning_rate": 2.18e-05,
      "loss": 3.2807,
      "step": 5640
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.05708122253418,
      "learning_rate": 2.175e-05,
      "loss": 3.1732,
      "step": 5650
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.683881759643555,
      "learning_rate": 2.1700000000000002e-05,
      "loss": 3.2047,
      "step": 5660
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.31165599822998,
      "learning_rate": 2.165e-05,
      "loss": 2.9987,
      "step": 5670
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.49854850769043,
      "learning_rate": 2.16e-05,
      "loss": 3.2406,
      "step": 5680
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.562043190002441,
      "learning_rate": 2.1550000000000002e-05,
      "loss": 3.3797,
      "step": 5690
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.994556427001953,
      "learning_rate": 2.15e-05,
      "loss": 3.2047,
      "step": 5700
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.670415878295898,
      "learning_rate": 2.145e-05,
      "loss": 3.3293,
      "step": 5710
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.37359619140625,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 3.3168,
      "step": 5720
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.210165023803711,
      "learning_rate": 2.135e-05,
      "loss": 3.2686,
      "step": 5730
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.961390495300293,
      "learning_rate": 2.13e-05,
      "loss": 3.1742,
      "step": 5740
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.470001220703125,
      "learning_rate": 2.125e-05,
      "loss": 3.443,
      "step": 5750
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.213688850402832,
      "learning_rate": 2.12e-05,
      "loss": 2.9912,
      "step": 5760
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.848333358764648,
      "learning_rate": 2.115e-05,
      "loss": 3.0979,
      "step": 5770
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.4463529586792,
      "learning_rate": 2.11e-05,
      "loss": 3.2219,
      "step": 5780
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.547118186950684,
      "learning_rate": 2.105e-05,
      "loss": 2.8422,
      "step": 5790
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.835119247436523,
      "learning_rate": 2.1e-05,
      "loss": 3.3445,
      "step": 5800
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.279208183288574,
      "learning_rate": 2.095e-05,
      "loss": 3.1572,
      "step": 5810
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.347326278686523,
      "learning_rate": 2.09e-05,
      "loss": 3.3471,
      "step": 5820
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.940796852111816,
      "learning_rate": 2.085e-05,
      "loss": 3.2803,
      "step": 5830
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.87930965423584,
      "learning_rate": 2.08e-05,
      "loss": 3.3746,
      "step": 5840
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.151037216186523,
      "learning_rate": 2.075e-05,
      "loss": 3.3986,
      "step": 5850
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.717418670654297,
      "learning_rate": 2.07e-05,
      "loss": 3.3316,
      "step": 5860
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.266892433166504,
      "learning_rate": 2.065e-05,
      "loss": 3.3951,
      "step": 5870
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.531266212463379,
      "learning_rate": 2.06e-05,
      "loss": 3.1939,
      "step": 5880
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.460736274719238,
      "learning_rate": 2.055e-05,
      "loss": 2.9258,
      "step": 5890
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.996274948120117,
      "learning_rate": 2.05e-05,
      "loss": 3.5455,
      "step": 5900
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.341967582702637,
      "learning_rate": 2.045e-05,
      "loss": 3.0949,
      "step": 5910
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.015793800354004,
      "learning_rate": 2.04e-05,
      "loss": 3.3463,
      "step": 5920
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.348493576049805,
      "learning_rate": 2.035e-05,
      "loss": 3.3473,
      "step": 5930
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.10364818572998,
      "learning_rate": 2.0300000000000002e-05,
      "loss": 3.4068,
      "step": 5940
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.629905700683594,
      "learning_rate": 2.025e-05,
      "loss": 3.1812,
      "step": 5950
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.790244102478027,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 3.3768,
      "step": 5960
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.592944145202637,
      "learning_rate": 2.0150000000000002e-05,
      "loss": 3.2555,
      "step": 5970
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.510038375854492,
      "learning_rate": 2.01e-05,
      "loss": 3.4383,
      "step": 5980
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.070319175720215,
      "learning_rate": 2.0050000000000003e-05,
      "loss": 3.1746,
      "step": 5990
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.608047485351562,
      "learning_rate": 2e-05,
      "loss": 3.4053,
      "step": 6000
    },
    {
      "epoch": 0.05,
      "eval_bleu-4": 0.04397874938865524,
      "eval_rouge-1": 32.19044,
      "eval_rouge-2": 7.479208000000001,
      "eval_rouge-l": 24.367095999999997,
      "eval_runtime": 44.2627,
      "eval_samples_per_second": 1.13,
      "eval_steps_per_second": 0.158,
      "step": 6000
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.99272632598877,
      "learning_rate": 1.995e-05,
      "loss": 3.1727,
      "step": 6010
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.038368225097656,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 3.2631,
      "step": 6020
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.26545238494873,
      "learning_rate": 1.985e-05,
      "loss": 3.2646,
      "step": 6030
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.312978744506836,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 3.2434,
      "step": 6040
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.410139083862305,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 3.1174,
      "step": 6050
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.035017013549805,
      "learning_rate": 1.97e-05,
      "loss": 3.1373,
      "step": 6060
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.595858573913574,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 3.3836,
      "step": 6070
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.05622386932373,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 3.308,
      "step": 6080
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.597272872924805,
      "learning_rate": 1.955e-05,
      "loss": 3.3195,
      "step": 6090
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.049637794494629,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 3.3314,
      "step": 6100
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.728287696838379,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 3.3537,
      "step": 6110
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.200684547424316,
      "learning_rate": 1.94e-05,
      "loss": 3.1877,
      "step": 6120
    },
    {
      "epoch": 0.05,
      "grad_norm": 22.20122528076172,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 3.2828,
      "step": 6130
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.452753067016602,
      "learning_rate": 1.93e-05,
      "loss": 3.0764,
      "step": 6140
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.830453872680664,
      "learning_rate": 1.925e-05,
      "loss": 3.4541,
      "step": 6150
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.653790473937988,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 3.2242,
      "step": 6160
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.252945899963379,
      "learning_rate": 1.915e-05,
      "loss": 3.427,
      "step": 6170
    },
    {
      "epoch": 0.05,
      "grad_norm": 15.898715019226074,
      "learning_rate": 1.91e-05,
      "loss": 3.41,
      "step": 6180
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.697982788085938,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 3.1389,
      "step": 6190
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.242137908935547,
      "learning_rate": 1.9e-05,
      "loss": 3.4299,
      "step": 6200
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.623505592346191,
      "learning_rate": 1.895e-05,
      "loss": 3.3047,
      "step": 6210
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.343210220336914,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 3.025,
      "step": 6220
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.180024147033691,
      "learning_rate": 1.885e-05,
      "loss": 3.4541,
      "step": 6230
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.270400047302246,
      "learning_rate": 1.88e-05,
      "loss": 3.3223,
      "step": 6240
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.222799301147461,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.2604,
      "step": 6250
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.885242462158203,
      "learning_rate": 1.87e-05,
      "loss": 3.2488,
      "step": 6260
    },
    {
      "epoch": 0.05,
      "grad_norm": 9.507349014282227,
      "learning_rate": 1.865e-05,
      "loss": 3.5156,
      "step": 6270
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.298604965209961,
      "learning_rate": 1.86e-05,
      "loss": 3.1861,
      "step": 6280
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.550804138183594,
      "learning_rate": 1.855e-05,
      "loss": 3.1037,
      "step": 6290
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.882097244262695,
      "learning_rate": 1.85e-05,
      "loss": 3.1982,
      "step": 6300
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.572385787963867,
      "learning_rate": 1.845e-05,
      "loss": 3.3312,
      "step": 6310
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.193718910217285,
      "learning_rate": 1.84e-05,
      "loss": 3.5832,
      "step": 6320
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.970232963562012,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 3.4738,
      "step": 6330
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.280266761779785,
      "learning_rate": 1.83e-05,
      "loss": 3.3246,
      "step": 6340
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.678982734680176,
      "learning_rate": 1.825e-05,
      "loss": 3.3672,
      "step": 6350
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.688116073608398,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 3.1779,
      "step": 6360
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.298575401306152,
      "learning_rate": 1.815e-05,
      "loss": 3.443,
      "step": 6370
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.759256362915039,
      "learning_rate": 1.81e-05,
      "loss": 3.2033,
      "step": 6380
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.350284576416016,
      "learning_rate": 1.805e-05,
      "loss": 3.323,
      "step": 6390
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.205513954162598,
      "learning_rate": 1.8e-05,
      "loss": 3.2762,
      "step": 6400
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.071640968322754,
      "learning_rate": 1.795e-05,
      "loss": 3.209,
      "step": 6410
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.831296920776367,
      "learning_rate": 1.79e-05,
      "loss": 3.3584,
      "step": 6420
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.987983703613281,
      "learning_rate": 1.785e-05,
      "loss": 3.2902,
      "step": 6430
    },
    {
      "epoch": 0.06,
      "grad_norm": 15.550010681152344,
      "learning_rate": 1.78e-05,
      "loss": 3.0391,
      "step": 6440
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.261195182800293,
      "learning_rate": 1.775e-05,
      "loss": 3.3236,
      "step": 6450
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.659759521484375,
      "learning_rate": 1.77e-05,
      "loss": 3.3502,
      "step": 6460
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.98594856262207,
      "learning_rate": 1.765e-05,
      "loss": 3.3156,
      "step": 6470
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.684590339660645,
      "learning_rate": 1.76e-05,
      "loss": 3.06,
      "step": 6480
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.465791702270508,
      "learning_rate": 1.755e-05,
      "loss": 3.3586,
      "step": 6490
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.01194953918457,
      "learning_rate": 1.75e-05,
      "loss": 3.234,
      "step": 6500
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.040693888397129306,
      "eval_rouge-1": 31.373340000000002,
      "eval_rouge-2": 7.093391999999999,
      "eval_rouge-l": 23.440264000000003,
      "eval_runtime": 72.7305,
      "eval_samples_per_second": 0.687,
      "eval_steps_per_second": 0.096,
      "step": 6500
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.201150894165039,
      "learning_rate": 1.745e-05,
      "loss": 3.3869,
      "step": 6510
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.071823120117188,
      "learning_rate": 1.74e-05,
      "loss": 3.2299,
      "step": 6520
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.5119047164917,
      "learning_rate": 1.7349999999999998e-05,
      "loss": 3.2184,
      "step": 6530
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.454326629638672,
      "learning_rate": 1.73e-05,
      "loss": 2.9768,
      "step": 6540
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.76469898223877,
      "learning_rate": 1.725e-05,
      "loss": 3.1877,
      "step": 6550
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.574040412902832,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 3.3832,
      "step": 6560
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.362608909606934,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 3.1605,
      "step": 6570
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.952844619750977,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 3.5781,
      "step": 6580
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.559200286865234,
      "learning_rate": 1.705e-05,
      "loss": 3.1551,
      "step": 6590
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.228923797607422,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 3.1473,
      "step": 6600
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.359844207763672,
      "learning_rate": 1.6950000000000002e-05,
      "loss": 3.325,
      "step": 6610
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.48997688293457,
      "learning_rate": 1.69e-05,
      "loss": 3.2662,
      "step": 6620
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.247655868530273,
      "learning_rate": 1.6850000000000003e-05,
      "loss": 2.984,
      "step": 6630
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.833203315734863,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 3.118,
      "step": 6640
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.058089256286621,
      "learning_rate": 1.675e-05,
      "loss": 3.5732,
      "step": 6650
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.921914100646973,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 3.2143,
      "step": 6660
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.609360694885254,
      "learning_rate": 1.665e-05,
      "loss": 3.2602,
      "step": 6670
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.925107955932617,
      "learning_rate": 1.66e-05,
      "loss": 3.1863,
      "step": 6680
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.05794906616211,
      "learning_rate": 1.6550000000000002e-05,
      "loss": 3.3188,
      "step": 6690
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.124201774597168,
      "learning_rate": 1.65e-05,
      "loss": 3.275,
      "step": 6700
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.06375503540039,
      "learning_rate": 1.645e-05,
      "loss": 2.9594,
      "step": 6710
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.462553024291992,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 3.2156,
      "step": 6720
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.619709968566895,
      "learning_rate": 1.635e-05,
      "loss": 3.2406,
      "step": 6730
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.282486915588379,
      "learning_rate": 1.63e-05,
      "loss": 3.1723,
      "step": 6740
    },
    {
      "epoch": 0.06,
      "grad_norm": 16.433738708496094,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 3.3021,
      "step": 6750
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.42672348022461,
      "learning_rate": 1.62e-05,
      "loss": 3.1922,
      "step": 6760
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.907121658325195,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 3.4152,
      "step": 6770
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.112516403198242,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 3.3822,
      "step": 6780
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.912538528442383,
      "learning_rate": 1.605e-05,
      "loss": 3.3279,
      "step": 6790
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.596590995788574,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.3029,
      "step": 6800
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.470540046691895,
      "learning_rate": 1.595e-05,
      "loss": 3.5791,
      "step": 6810
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.664467811584473,
      "learning_rate": 1.59e-05,
      "loss": 3.3391,
      "step": 6820
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.35627269744873,
      "learning_rate": 1.5850000000000002e-05,
      "loss": 3.0881,
      "step": 6830
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.324821472167969,
      "learning_rate": 1.58e-05,
      "loss": 3.3141,
      "step": 6840
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.985342025756836,
      "learning_rate": 1.575e-05,
      "loss": 3.2805,
      "step": 6850
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.318656921386719,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 3.342,
      "step": 6860
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.462021827697754,
      "learning_rate": 1.565e-05,
      "loss": 3.2107,
      "step": 6870
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.9635648727417,
      "learning_rate": 1.56e-05,
      "loss": 3.4951,
      "step": 6880
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.591937065124512,
      "learning_rate": 1.5550000000000002e-05,
      "loss": 3.4293,
      "step": 6890
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.646013259887695,
      "learning_rate": 1.55e-05,
      "loss": 3.1174,
      "step": 6900
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.487873077392578,
      "learning_rate": 1.545e-05,
      "loss": 3.4844,
      "step": 6910
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.075216293334961,
      "learning_rate": 1.54e-05,
      "loss": 3.1443,
      "step": 6920
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.76960563659668,
      "learning_rate": 1.535e-05,
      "loss": 3.3453,
      "step": 6930
    },
    {
      "epoch": 0.06,
      "grad_norm": 8.797869682312012,
      "learning_rate": 1.53e-05,
      "loss": 3.2354,
      "step": 6940
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.00033950805664,
      "learning_rate": 1.525e-05,
      "loss": 3.1168,
      "step": 6950
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.19289493560791,
      "learning_rate": 1.52e-05,
      "loss": 3.3307,
      "step": 6960
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.606234550476074,
      "learning_rate": 1.515e-05,
      "loss": 3.3465,
      "step": 6970
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.665130615234375,
      "learning_rate": 1.51e-05,
      "loss": 3.3072,
      "step": 6980
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.191620826721191,
      "learning_rate": 1.505e-05,
      "loss": 3.5678,
      "step": 6990
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.974055290222168,
      "learning_rate": 1.5e-05,
      "loss": 3.1092,
      "step": 7000
    },
    {
      "epoch": 0.06,
      "eval_bleu-4": 0.043049303370406966,
      "eval_rouge-1": 32.069618000000006,
      "eval_rouge-2": 7.523944000000001,
      "eval_rouge-l": 24.889566,
      "eval_runtime": 50.1352,
      "eval_samples_per_second": 0.997,
      "eval_steps_per_second": 0.14,
      "step": 7000
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.75197982788086,
      "learning_rate": 1.4950000000000001e-05,
      "loss": 3.3867,
      "step": 7010
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.801042556762695,
      "learning_rate": 1.49e-05,
      "loss": 3.3201,
      "step": 7020
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.080921173095703,
      "learning_rate": 1.485e-05,
      "loss": 3.3945,
      "step": 7030
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.248359680175781,
      "learning_rate": 1.48e-05,
      "loss": 3.2459,
      "step": 7040
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.726625442504883,
      "learning_rate": 1.475e-05,
      "loss": 3.1193,
      "step": 7050
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.332340240478516,
      "learning_rate": 1.47e-05,
      "loss": 3.274,
      "step": 7060
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.699294090270996,
      "learning_rate": 1.465e-05,
      "loss": 3.4658,
      "step": 7070
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.921307563781738,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 3.1643,
      "step": 7080
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.923645973205566,
      "learning_rate": 1.455e-05,
      "loss": 3.2398,
      "step": 7090
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.518800735473633,
      "learning_rate": 1.45e-05,
      "loss": 3.1152,
      "step": 7100
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.550752639770508,
      "learning_rate": 1.4449999999999999e-05,
      "loss": 3.2225,
      "step": 7110
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.14362907409668,
      "learning_rate": 1.44e-05,
      "loss": 3.166,
      "step": 7120
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.608399391174316,
      "learning_rate": 1.435e-05,
      "loss": 3.1973,
      "step": 7130
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.297202110290527,
      "learning_rate": 1.43e-05,
      "loss": 3.2918,
      "step": 7140
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.505513191223145,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 3.1207,
      "step": 7150
    },
    {
      "epoch": 0.06,
      "grad_norm": 15.506170272827148,
      "learning_rate": 1.42e-05,
      "loss": 3.4295,
      "step": 7160
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.145000457763672,
      "learning_rate": 1.415e-05,
      "loss": 3.3447,
      "step": 7170
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.522090911865234,
      "learning_rate": 1.4099999999999999e-05,
      "loss": 3.1592,
      "step": 7180
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.720244407653809,
      "learning_rate": 1.4050000000000003e-05,
      "loss": 3.0125,
      "step": 7190
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.939790725708008,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.3406,
      "step": 7200
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.312626838684082,
      "learning_rate": 1.3950000000000002e-05,
      "loss": 3.5277,
      "step": 7210
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.8878173828125,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 3.2025,
      "step": 7220
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.61461067199707,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 3.2248,
      "step": 7230
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.088717460632324,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 2.9766,
      "step": 7240
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.17527961730957,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 3.1658,
      "step": 7250
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.873486518859863,
      "learning_rate": 1.3700000000000001e-05,
      "loss": 3.2049,
      "step": 7260
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.227071762084961,
      "learning_rate": 1.3650000000000001e-05,
      "loss": 3.4189,
      "step": 7270
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.738506317138672,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 3.2074,
      "step": 7280
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.683344841003418,
      "learning_rate": 1.3550000000000002e-05,
      "loss": 3.4588,
      "step": 7290
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.004629135131836,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 3.2559,
      "step": 7300
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.690478324890137,
      "learning_rate": 1.3450000000000002e-05,
      "loss": 3.5818,
      "step": 7310
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.712722778320312,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 3.5002,
      "step": 7320
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.043072700500488,
      "learning_rate": 1.3350000000000001e-05,
      "loss": 3.1629,
      "step": 7330
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.855975151062012,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 3.0746,
      "step": 7340
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.285235404968262,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 3.2939,
      "step": 7350
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.520979881286621,
      "learning_rate": 1.32e-05,
      "loss": 3.3223,
      "step": 7360
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.922901153564453,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 3.168,
      "step": 7370
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.43078327178955,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 3.0014,
      "step": 7380
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.420799255371094,
      "learning_rate": 1.305e-05,
      "loss": 3.5414,
      "step": 7390
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.645529747009277,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.5934,
      "step": 7400
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.27762508392334,
      "learning_rate": 1.2950000000000001e-05,
      "loss": 3.3586,
      "step": 7410
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.47005844116211,
      "learning_rate": 1.29e-05,
      "loss": 3.0633,
      "step": 7420
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.48521614074707,
      "learning_rate": 1.285e-05,
      "loss": 3.283,
      "step": 7430
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.003236770629883,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 3.257,
      "step": 7440
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.037175178527832,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 3.3445,
      "step": 7450
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.153943061828613,
      "learning_rate": 1.27e-05,
      "loss": 3.0598,
      "step": 7460
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.88210391998291,
      "learning_rate": 1.2650000000000001e-05,
      "loss": 3.0703,
      "step": 7470
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.070176124572754,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 3.266,
      "step": 7480
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.497685432434082,
      "learning_rate": 1.255e-05,
      "loss": 3.1641,
      "step": 7490
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.557469367980957,
      "learning_rate": 1.25e-05,
      "loss": 3.0127,
      "step": 7500
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.039211197066706636,
      "eval_rouge-1": 31.182836,
      "eval_rouge-2": 7.120878,
      "eval_rouge-l": 24.142132,
      "eval_runtime": 51.6676,
      "eval_samples_per_second": 0.968,
      "eval_steps_per_second": 0.135,
      "step": 7500
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.805798530578613,
      "learning_rate": 1.2450000000000001e-05,
      "loss": 3.4551,
      "step": 7510
    },
    {
      "epoch": 0.07,
      "grad_norm": 19.0662899017334,
      "learning_rate": 1.24e-05,
      "loss": 3.0834,
      "step": 7520
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.212971687316895,
      "learning_rate": 1.235e-05,
      "loss": 3.3395,
      "step": 7530
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.525588035583496,
      "learning_rate": 1.23e-05,
      "loss": 3.2482,
      "step": 7540
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.850332260131836,
      "learning_rate": 1.225e-05,
      "loss": 3.3689,
      "step": 7550
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.28227424621582,
      "learning_rate": 1.22e-05,
      "loss": 3.1361,
      "step": 7560
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.092460632324219,
      "learning_rate": 1.215e-05,
      "loss": 3.3975,
      "step": 7570
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.3156156539917,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 3.1088,
      "step": 7580
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.066588401794434,
      "learning_rate": 1.205e-05,
      "loss": 3.2346,
      "step": 7590
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.79503059387207,
      "learning_rate": 1.2e-05,
      "loss": 3.1986,
      "step": 7600
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.223899841308594,
      "learning_rate": 1.195e-05,
      "loss": 3.1586,
      "step": 7610
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.671683311462402,
      "learning_rate": 1.19e-05,
      "loss": 3.3795,
      "step": 7620
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.700738906860352,
      "learning_rate": 1.185e-05,
      "loss": 3.2283,
      "step": 7630
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.788260459899902,
      "learning_rate": 1.18e-05,
      "loss": 3.3391,
      "step": 7640
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.720216751098633,
      "learning_rate": 1.175e-05,
      "loss": 3.2244,
      "step": 7650
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.038411140441895,
      "learning_rate": 1.1700000000000001e-05,
      "loss": 3.4809,
      "step": 7660
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.374079704284668,
      "learning_rate": 1.1650000000000002e-05,
      "loss": 3.457,
      "step": 7670
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.181798934936523,
      "learning_rate": 1.16e-05,
      "loss": 3.2701,
      "step": 7680
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.018261909484863,
      "learning_rate": 1.1550000000000001e-05,
      "loss": 2.9729,
      "step": 7690
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.778820991516113,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 3.015,
      "step": 7700
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.279982566833496,
      "learning_rate": 1.145e-05,
      "loss": 3.2115,
      "step": 7710
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.89324951171875,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 3.4174,
      "step": 7720
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.885979652404785,
      "learning_rate": 1.1350000000000001e-05,
      "loss": 3.3236,
      "step": 7730
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.204290390014648,
      "learning_rate": 1.13e-05,
      "loss": 3.4035,
      "step": 7740
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.897521018981934,
      "learning_rate": 1.125e-05,
      "loss": 3.4297,
      "step": 7750
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.653059959411621,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 3.3094,
      "step": 7760
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.893285751342773,
      "learning_rate": 1.115e-05,
      "loss": 3.2938,
      "step": 7770
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.78653621673584,
      "learning_rate": 1.11e-05,
      "loss": 3.1494,
      "step": 7780
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.802620887756348,
      "learning_rate": 1.1050000000000001e-05,
      "loss": 3.266,
      "step": 7790
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.427569389343262,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 3.0953,
      "step": 7800
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.700285911560059,
      "learning_rate": 1.095e-05,
      "loss": 3.0932,
      "step": 7810
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.357247352600098,
      "learning_rate": 1.09e-05,
      "loss": 3.1109,
      "step": 7820
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.027987480163574,
      "learning_rate": 1.0850000000000001e-05,
      "loss": 3.3717,
      "step": 7830
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.430400848388672,
      "learning_rate": 1.08e-05,
      "loss": 3.0908,
      "step": 7840
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.229496002197266,
      "learning_rate": 1.075e-05,
      "loss": 3.1437,
      "step": 7850
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.54151439666748,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 3.2232,
      "step": 7860
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.926546096801758,
      "learning_rate": 1.065e-05,
      "loss": 3.3434,
      "step": 7870
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.229780197143555,
      "learning_rate": 1.06e-05,
      "loss": 3.3219,
      "step": 7880
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.36108112335205,
      "learning_rate": 1.055e-05,
      "loss": 3.1625,
      "step": 7890
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.069937705993652,
      "learning_rate": 1.05e-05,
      "loss": 2.8668,
      "step": 7900
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.574789047241211,
      "learning_rate": 1.045e-05,
      "loss": 3.2824,
      "step": 7910
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.159462928771973,
      "learning_rate": 1.04e-05,
      "loss": 3.2158,
      "step": 7920
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.874090194702148,
      "learning_rate": 1.035e-05,
      "loss": 3.5203,
      "step": 7930
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.125391006469727,
      "learning_rate": 1.03e-05,
      "loss": 3.1756,
      "step": 7940
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.221755027770996,
      "learning_rate": 1.025e-05,
      "loss": 3.216,
      "step": 7950
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.240377426147461,
      "learning_rate": 1.02e-05,
      "loss": 3.1887,
      "step": 7960
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.366555213928223,
      "learning_rate": 1.0150000000000001e-05,
      "loss": 3.1588,
      "step": 7970
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.572724342346191,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 3.217,
      "step": 7980
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.49856185913086,
      "learning_rate": 1.005e-05,
      "loss": 3.4564,
      "step": 7990
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.84931755065918,
      "learning_rate": 1e-05,
      "loss": 3.3357,
      "step": 8000
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.042684953615868305,
      "eval_rouge-1": 30.90497,
      "eval_rouge-2": 7.299856,
      "eval_rouge-l": 24.491508,
      "eval_runtime": 49.8612,
      "eval_samples_per_second": 1.003,
      "eval_steps_per_second": 0.14,
      "step": 8000
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.17078685760498,
      "learning_rate": 9.950000000000001e-06,
      "loss": 3.434,
      "step": 8010
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.754704475402832,
      "learning_rate": 9.900000000000002e-06,
      "loss": 3.1191,
      "step": 8020
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.363862991333008,
      "learning_rate": 9.85e-06,
      "loss": 3.2447,
      "step": 8030
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.543548583984375,
      "learning_rate": 9.800000000000001e-06,
      "loss": 3.2945,
      "step": 8040
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.123888969421387,
      "learning_rate": 9.750000000000002e-06,
      "loss": 3.4834,
      "step": 8050
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.661100387573242,
      "learning_rate": 9.7e-06,
      "loss": 3.3469,
      "step": 8060
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.913171768188477,
      "learning_rate": 9.65e-06,
      "loss": 3.2463,
      "step": 8070
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.93600082397461,
      "learning_rate": 9.600000000000001e-06,
      "loss": 3.3441,
      "step": 8080
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.659448623657227,
      "learning_rate": 9.55e-06,
      "loss": 3.4262,
      "step": 8090
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.664579391479492,
      "learning_rate": 9.5e-06,
      "loss": 3.498,
      "step": 8100
    },
    {
      "epoch": 0.07,
      "grad_norm": 19.737504959106445,
      "learning_rate": 9.450000000000001e-06,
      "loss": 3.3619,
      "step": 8110
    },
    {
      "epoch": 0.07,
      "grad_norm": 17.000274658203125,
      "learning_rate": 9.4e-06,
      "loss": 3.3877,
      "step": 8120
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.793052673339844,
      "learning_rate": 9.35e-06,
      "loss": 3.2811,
      "step": 8130
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.287823677062988,
      "learning_rate": 9.3e-06,
      "loss": 3.2588,
      "step": 8140
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.04907512664795,
      "learning_rate": 9.25e-06,
      "loss": 3.1352,
      "step": 8150
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.510705947875977,
      "learning_rate": 9.2e-06,
      "loss": 3.7072,
      "step": 8160
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.48420524597168,
      "learning_rate": 9.15e-06,
      "loss": 3.3508,
      "step": 8170
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.637042045593262,
      "learning_rate": 9.100000000000001e-06,
      "loss": 3.1645,
      "step": 8180
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.268486976623535,
      "learning_rate": 9.05e-06,
      "loss": 3.1119,
      "step": 8190
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.204133987426758,
      "learning_rate": 9e-06,
      "loss": 3.3139,
      "step": 8200
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.493224143981934,
      "learning_rate": 8.95e-06,
      "loss": 3.248,
      "step": 8210
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.091323852539062,
      "learning_rate": 8.9e-06,
      "loss": 3.1865,
      "step": 8220
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.527972221374512,
      "learning_rate": 8.85e-06,
      "loss": 3.2164,
      "step": 8230
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.554596900939941,
      "learning_rate": 8.8e-06,
      "loss": 3.0273,
      "step": 8240
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.863637924194336,
      "learning_rate": 8.75e-06,
      "loss": 3.176,
      "step": 8250
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.17138957977295,
      "learning_rate": 8.7e-06,
      "loss": 3.6053,
      "step": 8260
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.581439971923828,
      "learning_rate": 8.65e-06,
      "loss": 3.2963,
      "step": 8270
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.540253639221191,
      "learning_rate": 8.599999999999999e-06,
      "loss": 3.118,
      "step": 8280
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.323785781860352,
      "learning_rate": 8.550000000000001e-06,
      "loss": 3.1953,
      "step": 8290
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.247026443481445,
      "learning_rate": 8.500000000000002e-06,
      "loss": 3.4619,
      "step": 8300
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.65580940246582,
      "learning_rate": 8.45e-06,
      "loss": 3.3244,
      "step": 8310
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.942821502685547,
      "learning_rate": 8.400000000000001e-06,
      "loss": 3.0967,
      "step": 8320
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.988136291503906,
      "learning_rate": 8.350000000000001e-06,
      "loss": 3.0971,
      "step": 8330
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.96632194519043,
      "learning_rate": 8.3e-06,
      "loss": 3.21,
      "step": 8340
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.110424995422363,
      "learning_rate": 8.25e-06,
      "loss": 3.4436,
      "step": 8350
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.454316139221191,
      "learning_rate": 8.200000000000001e-06,
      "loss": 3.4881,
      "step": 8360
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.125728607177734,
      "learning_rate": 8.15e-06,
      "loss": 3.0105,
      "step": 8370
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.519767761230469,
      "learning_rate": 8.1e-06,
      "loss": 3.2402,
      "step": 8380
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.869256019592285,
      "learning_rate": 8.050000000000001e-06,
      "loss": 3.4172,
      "step": 8390
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.107439994812012,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.3281,
      "step": 8400
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.901073455810547,
      "learning_rate": 7.95e-06,
      "loss": 3.2877,
      "step": 8410
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.231179237365723,
      "learning_rate": 7.9e-06,
      "loss": 3.2939,
      "step": 8420
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.691634178161621,
      "learning_rate": 7.850000000000001e-06,
      "loss": 3.1674,
      "step": 8430
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.05400276184082,
      "learning_rate": 7.8e-06,
      "loss": 2.9537,
      "step": 8440
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.31533145904541,
      "learning_rate": 7.75e-06,
      "loss": 3.5164,
      "step": 8450
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.715703010559082,
      "learning_rate": 7.7e-06,
      "loss": 3.4939,
      "step": 8460
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.954360961914062,
      "learning_rate": 7.65e-06,
      "loss": 3.3945,
      "step": 8470
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.749613761901855,
      "learning_rate": 7.6e-06,
      "loss": 3.4959,
      "step": 8480
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.773598670959473,
      "learning_rate": 7.55e-06,
      "loss": 3.167,
      "step": 8490
    },
    {
      "epoch": 0.07,
      "grad_norm": 11.611124992370605,
      "learning_rate": 7.5e-06,
      "loss": 2.9602,
      "step": 8500
    },
    {
      "epoch": 0.07,
      "eval_bleu-4": 0.03999863932117549,
      "eval_rouge-1": 31.383142000000003,
      "eval_rouge-2": 7.545961999999999,
      "eval_rouge-l": 23.890247999999996,
      "eval_runtime": 64.7806,
      "eval_samples_per_second": 0.772,
      "eval_steps_per_second": 0.108,
      "step": 8500
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.96755313873291,
      "learning_rate": 7.45e-06,
      "loss": 3.41,
      "step": 8510
    },
    {
      "epoch": 0.07,
      "grad_norm": 10.633173942565918,
      "learning_rate": 7.4e-06,
      "loss": 3.0562,
      "step": 8520
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.852649688720703,
      "learning_rate": 7.35e-06,
      "loss": 3.4717,
      "step": 8530
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.268315315246582,
      "learning_rate": 7.2999999999999996e-06,
      "loss": 2.9918,
      "step": 8540
    },
    {
      "epoch": 0.07,
      "grad_norm": 9.355266571044922,
      "learning_rate": 7.25e-06,
      "loss": 3.4268,
      "step": 8550
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.317142486572266,
      "learning_rate": 7.2e-06,
      "loss": 3.1168,
      "step": 8560
    },
    {
      "epoch": 0.07,
      "grad_norm": 19.56186866760254,
      "learning_rate": 7.15e-06,
      "loss": 3.2602,
      "step": 8570
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.622480392456055,
      "learning_rate": 7.1e-06,
      "loss": 3.1756,
      "step": 8580
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.538922309875488,
      "learning_rate": 7.049999999999999e-06,
      "loss": 3.2273,
      "step": 8590
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.738168716430664,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.402,
      "step": 8600
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.534613609313965,
      "learning_rate": 6.950000000000001e-06,
      "loss": 3.5141,
      "step": 8610
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.282466888427734,
      "learning_rate": 6.900000000000001e-06,
      "loss": 3.457,
      "step": 8620
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.95114517211914,
      "learning_rate": 6.8500000000000005e-06,
      "loss": 3.1699,
      "step": 8630
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.336073875427246,
      "learning_rate": 6.800000000000001e-06,
      "loss": 3.4318,
      "step": 8640
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.842538833618164,
      "learning_rate": 6.750000000000001e-06,
      "loss": 2.8877,
      "step": 8650
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.151583671569824,
      "learning_rate": 6.700000000000001e-06,
      "loss": 3.3803,
      "step": 8660
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.768706321716309,
      "learning_rate": 6.650000000000001e-06,
      "loss": 3.4432,
      "step": 8670
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.439598083496094,
      "learning_rate": 6.6e-06,
      "loss": 3.1844,
      "step": 8680
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.954757690429688,
      "learning_rate": 6.550000000000001e-06,
      "loss": 3.0756,
      "step": 8690
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.04234790802002,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 3.4939,
      "step": 8700
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.30992603302002,
      "learning_rate": 6.45e-06,
      "loss": 3.4324,
      "step": 8710
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.458271980285645,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 3.1428,
      "step": 8720
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.000770568847656,
      "learning_rate": 6.35e-06,
      "loss": 3.3168,
      "step": 8730
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.499648094177246,
      "learning_rate": 6.300000000000001e-06,
      "loss": 3.2072,
      "step": 8740
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.206503868103027,
      "learning_rate": 6.25e-06,
      "loss": 3.2916,
      "step": 8750
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.869928359985352,
      "learning_rate": 6.2e-06,
      "loss": 2.9779,
      "step": 8760
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.311086654663086,
      "learning_rate": 6.15e-06,
      "loss": 3.4061,
      "step": 8770
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.278440475463867,
      "learning_rate": 6.1e-06,
      "loss": 3.3641,
      "step": 8780
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.096010208129883,
      "learning_rate": 6.0500000000000005e-06,
      "loss": 3.2229,
      "step": 8790
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.615649223327637,
      "learning_rate": 6e-06,
      "loss": 3.2428,
      "step": 8800
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.054152488708496,
      "learning_rate": 5.95e-06,
      "loss": 3.1332,
      "step": 8810
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.891570091247559,
      "learning_rate": 5.9e-06,
      "loss": 3.3564,
      "step": 8820
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.716926574707031,
      "learning_rate": 5.850000000000001e-06,
      "loss": 3.5799,
      "step": 8830
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.073634147644043,
      "learning_rate": 5.8e-06,
      "loss": 3.1209,
      "step": 8840
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.852913856506348,
      "learning_rate": 5.750000000000001e-06,
      "loss": 3.2383,
      "step": 8850
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.648802757263184,
      "learning_rate": 5.7000000000000005e-06,
      "loss": 3.5889,
      "step": 8860
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.689404487609863,
      "learning_rate": 5.65e-06,
      "loss": 3.3557,
      "step": 8870
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.342035293579102,
      "learning_rate": 5.600000000000001e-06,
      "loss": 2.9649,
      "step": 8880
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.024179458618164,
      "learning_rate": 5.55e-06,
      "loss": 3.3881,
      "step": 8890
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.179282188415527,
      "learning_rate": 5.500000000000001e-06,
      "loss": 3.2625,
      "step": 8900
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.185065269470215,
      "learning_rate": 5.45e-06,
      "loss": 3.1492,
      "step": 8910
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.480470657348633,
      "learning_rate": 5.4e-06,
      "loss": 3.2273,
      "step": 8920
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.60818099975586,
      "learning_rate": 5.3500000000000004e-06,
      "loss": 3.2814,
      "step": 8930
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.290116310119629,
      "learning_rate": 5.3e-06,
      "loss": 3.3107,
      "step": 8940
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.477456092834473,
      "learning_rate": 5.25e-06,
      "loss": 3.0033,
      "step": 8950
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.437301635742188,
      "learning_rate": 5.2e-06,
      "loss": 3.4664,
      "step": 8960
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.812216758728027,
      "learning_rate": 5.15e-06,
      "loss": 3.2104,
      "step": 8970
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.123600006103516,
      "learning_rate": 5.1e-06,
      "loss": 3.213,
      "step": 8980
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.029090881347656,
      "learning_rate": 5.050000000000001e-06,
      "loss": 3.0434,
      "step": 8990
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.369293212890625,
      "learning_rate": 5e-06,
      "loss": 3.1131,
      "step": 9000
    },
    {
      "epoch": 0.08,
      "eval_bleu-4": 0.04127872261312067,
      "eval_rouge-1": 31.82713,
      "eval_rouge-2": 7.469594,
      "eval_rouge-l": 23.245642000000004,
      "eval_runtime": 73.7346,
      "eval_samples_per_second": 0.678,
      "eval_steps_per_second": 0.095,
      "step": 9000
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.646988868713379,
      "learning_rate": 4.950000000000001e-06,
      "loss": 3.516,
      "step": 9010
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.99616527557373,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 3.4051,
      "step": 9020
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.974935531616211,
      "learning_rate": 4.85e-06,
      "loss": 2.8305,
      "step": 9030
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.582959175109863,
      "learning_rate": 4.800000000000001e-06,
      "loss": 3.1477,
      "step": 9040
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.044593811035156,
      "learning_rate": 4.75e-06,
      "loss": 3.284,
      "step": 9050
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.667963981628418,
      "learning_rate": 4.7e-06,
      "loss": 3.423,
      "step": 9060
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.803057670593262,
      "learning_rate": 4.65e-06,
      "loss": 3.0834,
      "step": 9070
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.14932918548584,
      "learning_rate": 4.6e-06,
      "loss": 3.4158,
      "step": 9080
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.828328132629395,
      "learning_rate": 4.5500000000000005e-06,
      "loss": 3.1645,
      "step": 9090
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.216590881347656,
      "learning_rate": 4.5e-06,
      "loss": 3.4133,
      "step": 9100
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.373024940490723,
      "learning_rate": 4.45e-06,
      "loss": 3.3254,
      "step": 9110
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.59012222290039,
      "learning_rate": 4.4e-06,
      "loss": 3.351,
      "step": 9120
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.524079322814941,
      "learning_rate": 4.35e-06,
      "loss": 3.0672,
      "step": 9130
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.371708869934082,
      "learning_rate": 4.2999999999999995e-06,
      "loss": 3.0162,
      "step": 9140
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.782759666442871,
      "learning_rate": 4.250000000000001e-06,
      "loss": 3.2363,
      "step": 9150
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.132872581481934,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 3.2027,
      "step": 9160
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.276668548583984,
      "learning_rate": 4.15e-06,
      "loss": 3.1479,
      "step": 9170
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.770621299743652,
      "learning_rate": 4.1000000000000006e-06,
      "loss": 3.2717,
      "step": 9180
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.406925201416016,
      "learning_rate": 4.05e-06,
      "loss": 3.3332,
      "step": 9190
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.693686485290527,
      "learning_rate": 4.000000000000001e-06,
      "loss": 3.1473,
      "step": 9200
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.296751022338867,
      "learning_rate": 3.95e-06,
      "loss": 3.0982,
      "step": 9210
    },
    {
      "epoch": 0.08,
      "grad_norm": 15.416574478149414,
      "learning_rate": 3.9e-06,
      "loss": 3.2365,
      "step": 9220
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.382184028625488,
      "learning_rate": 3.85e-06,
      "loss": 3.109,
      "step": 9230
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.155359268188477,
      "learning_rate": 3.8e-06,
      "loss": 3.2078,
      "step": 9240
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.53066635131836,
      "learning_rate": 3.75e-06,
      "loss": 3.1941,
      "step": 9250
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.241659164428711,
      "learning_rate": 3.7e-06,
      "loss": 3.4475,
      "step": 9260
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.106024742126465,
      "learning_rate": 3.6499999999999998e-06,
      "loss": 3.0137,
      "step": 9270
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.888422966003418,
      "learning_rate": 3.6e-06,
      "loss": 3.208,
      "step": 9280
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.153480529785156,
      "learning_rate": 3.55e-06,
      "loss": 3.1018,
      "step": 9290
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.327841758728027,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 3.3852,
      "step": 9300
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.65255355834961,
      "learning_rate": 3.4500000000000004e-06,
      "loss": 3.157,
      "step": 9310
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.485487937927246,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 3.25,
      "step": 9320
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.136491775512695,
      "learning_rate": 3.3500000000000005e-06,
      "loss": 3.4598,
      "step": 9330
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.514718055725098,
      "learning_rate": 3.3e-06,
      "loss": 3.2568,
      "step": 9340
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.67215633392334,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 3.2311,
      "step": 9350
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.215576171875,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 3.0451,
      "step": 9360
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.273390769958496,
      "learning_rate": 3.1500000000000003e-06,
      "loss": 2.7555,
      "step": 9370
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.737188339233398,
      "learning_rate": 3.1e-06,
      "loss": 3.1836,
      "step": 9380
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.489566802978516,
      "learning_rate": 3.05e-06,
      "loss": 3.2045,
      "step": 9390
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.402253150939941,
      "learning_rate": 3e-06,
      "loss": 3.3385,
      "step": 9400
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.24642562866211,
      "learning_rate": 2.95e-06,
      "loss": 3.0846,
      "step": 9410
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.147180557250977,
      "learning_rate": 2.9e-06,
      "loss": 3.1945,
      "step": 9420
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.919188499450684,
      "learning_rate": 2.8500000000000002e-06,
      "loss": 3.4336,
      "step": 9430
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.876119613647461,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 3.398,
      "step": 9440
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.934541702270508,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 3.4047,
      "step": 9450
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.742498397827148,
      "learning_rate": 2.7e-06,
      "loss": 3.1885,
      "step": 9460
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.468141555786133,
      "learning_rate": 2.65e-06,
      "loss": 2.9754,
      "step": 9470
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.661518096923828,
      "learning_rate": 2.6e-06,
      "loss": 3.1383,
      "step": 9480
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.133749008178711,
      "learning_rate": 2.55e-06,
      "loss": 3.5582,
      "step": 9490
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.694581031799316,
      "learning_rate": 2.5e-06,
      "loss": 3.1561,
      "step": 9500
    },
    {
      "epoch": 0.08,
      "eval_bleu-4": 0.043687376195995685,
      "eval_rouge-1": 31.949302,
      "eval_rouge-2": 7.819141999999999,
      "eval_rouge-l": 24.216545999999997,
      "eval_runtime": 61.1898,
      "eval_samples_per_second": 0.817,
      "eval_steps_per_second": 0.114,
      "step": 9500
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.086892127990723,
      "learning_rate": 2.4500000000000003e-06,
      "loss": 3.3801,
      "step": 9510
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.548357009887695,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 3.4482,
      "step": 9520
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.681182861328125,
      "learning_rate": 2.35e-06,
      "loss": 2.9502,
      "step": 9530
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.039548873901367,
      "learning_rate": 2.3e-06,
      "loss": 3.2803,
      "step": 9540
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.540130615234375,
      "learning_rate": 2.25e-06,
      "loss": 3.1879,
      "step": 9550
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.003935813903809,
      "learning_rate": 2.2e-06,
      "loss": 2.9891,
      "step": 9560
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.929858207702637,
      "learning_rate": 2.1499999999999997e-06,
      "loss": 3.2482,
      "step": 9570
    },
    {
      "epoch": 0.08,
      "grad_norm": 15.010950088500977,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 3.3707,
      "step": 9580
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.987396240234375,
      "learning_rate": 2.0500000000000003e-06,
      "loss": 3.4371,
      "step": 9590
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.853178024291992,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.0518,
      "step": 9600
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.410828590393066,
      "learning_rate": 1.95e-06,
      "loss": 3.5125,
      "step": 9610
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.833746910095215,
      "learning_rate": 1.9e-06,
      "loss": 3.3217,
      "step": 9620
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.020329475402832,
      "learning_rate": 1.85e-06,
      "loss": 3.2535,
      "step": 9630
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.632552146911621,
      "learning_rate": 1.8e-06,
      "loss": 3.2775,
      "step": 9640
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.120698928833008,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 3.1836,
      "step": 9650
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.916296005249023,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 3.0867,
      "step": 9660
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.927382469177246,
      "learning_rate": 1.65e-06,
      "loss": 3.2973,
      "step": 9670
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.050600051879883,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 3.0906,
      "step": 9680
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.571857452392578,
      "learning_rate": 1.55e-06,
      "loss": 3.3514,
      "step": 9690
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.869943618774414,
      "learning_rate": 1.5e-06,
      "loss": 3.3898,
      "step": 9700
    },
    {
      "epoch": 0.08,
      "grad_norm": 10.742258071899414,
      "learning_rate": 1.45e-06,
      "loss": 3.1613,
      "step": 9710
    },
    {
      "epoch": 0.08,
      "grad_norm": 9.86378002166748,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 2.8859,
      "step": 9720
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.194265365600586,
      "learning_rate": 1.35e-06,
      "loss": 3.1598,
      "step": 9730
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.179563522338867,
      "learning_rate": 1.3e-06,
      "loss": 3.1154,
      "step": 9740
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.753344535827637,
      "learning_rate": 1.25e-06,
      "loss": 3.3475,
      "step": 9750
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.998383522033691,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 3.4346,
      "step": 9760
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.707969665527344,
      "learning_rate": 1.15e-06,
      "loss": 3.1295,
      "step": 9770
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.831155776977539,
      "learning_rate": 1.1e-06,
      "loss": 3.0824,
      "step": 9780
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.141709327697754,
      "learning_rate": 1.0500000000000001e-06,
      "loss": 3.057,
      "step": 9790
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.121495246887207,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 3.376,
      "step": 9800
    },
    {
      "epoch": 0.09,
      "grad_norm": 16.152877807617188,
      "learning_rate": 9.5e-07,
      "loss": 3.3447,
      "step": 9810
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.975140571594238,
      "learning_rate": 9e-07,
      "loss": 3.2297,
      "step": 9820
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.33650016784668,
      "learning_rate": 8.500000000000001e-07,
      "loss": 3.0941,
      "step": 9830
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.403511047363281,
      "learning_rate": 8.000000000000001e-07,
      "loss": 3.0773,
      "step": 9840
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.2567777633667,
      "learning_rate": 7.5e-07,
      "loss": 3.1963,
      "step": 9850
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.90089225769043,
      "learning_rate": 7.000000000000001e-07,
      "loss": 3.3721,
      "step": 9860
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.030193328857422,
      "learning_rate": 6.5e-07,
      "loss": 3.0449,
      "step": 9870
    },
    {
      "epoch": 0.09,
      "grad_norm": 9.538484573364258,
      "learning_rate": 6.000000000000001e-07,
      "loss": 2.9623,
      "step": 9880
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.186580657958984,
      "learning_rate": 5.5e-07,
      "loss": 3.2338,
      "step": 9890
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.856864929199219,
      "learning_rate": 5.000000000000001e-07,
      "loss": 3.4701,
      "step": 9900
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.514665603637695,
      "learning_rate": 4.5e-07,
      "loss": 3.3902,
      "step": 9910
    },
    {
      "epoch": 0.09,
      "grad_norm": 10.241944313049316,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 3.1645,
      "step": 9920
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.3910493850708,
      "learning_rate": 3.5000000000000004e-07,
      "loss": 3.0738,
      "step": 9930
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.598583221435547,
      "learning_rate": 3.0000000000000004e-07,
      "loss": 3.1572,
      "step": 9940
    },
    {
      "epoch": 0.09,
      "grad_norm": 16.14068031311035,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 3.6637,
      "step": 9950
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.076881408691406,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 3.474,
      "step": 9960
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.466094017028809,
      "learning_rate": 1.5000000000000002e-07,
      "loss": 3.2357,
      "step": 9970
    },
    {
      "epoch": 0.09,
      "grad_norm": 12.939879417419434,
      "learning_rate": 1.0000000000000001e-07,
      "loss": 3.2371,
      "step": 9980
    },
    {
      "epoch": 0.09,
      "grad_norm": 11.156267166137695,
      "learning_rate": 5.0000000000000004e-08,
      "loss": 3.2783,
      "step": 9990
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.038909912109375,
      "learning_rate": 0.0,
      "loss": 3.3422,
      "step": 10000
    },
    {
      "epoch": 0.09,
      "eval_bleu-4": 0.0420185410754745,
      "eval_rouge-1": 32.00971,
      "eval_rouge-2": 7.6954259999999985,
      "eval_rouge-l": 24.208880000000004,
      "eval_runtime": 73.4679,
      "eval_samples_per_second": 0.681,
      "eval_steps_per_second": 0.095,
      "step": 10000
    }
  ],
  "logging_steps": 10,
  "max_steps": 10000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "total_flos": 4.149447997335552e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
